{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-etiquetado-manual+svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jaiio/modelos/01-etiquetado_manual%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Baseline JAIIO: Etiquetado manual+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos sobre la estrategia de representación y técnica de aprendizaje *baseline* utilizada para JAIIO con los correos etiquetados de forma manual.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLanwDJVnFF"
      },
      "source": [
        "## Instalación y Carga de librerías y funciones útiles\n",
        "\n",
        "### Instalación de librerías\n",
        "\n",
        "Se instalan las librerías que no están en el entorno de Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644uDER_VnXj",
        "outputId": "26dc0c0e-768d-4014-b08b-2af3a34df0a4"
      },
      "source": [
        "# Se instala gensim que es el que tiene el modelo Word2Vec\n",
        "!pip install requests\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=0365b93daedc1cf04ae718891182d08fbeb566fe61d650ad5b5e0fd25a680319\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fDuhK2V1kx"
      },
      "source": [
        "### Funciones útiles\n",
        "\n",
        "Se cargan funciones útiles desde el repo https://github.com/jumafernandez/clasificacion_correos para la carga y balanceo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_dataset.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_dataset.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_dataset import get_clases, cargar_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxjaGIfV-rT"
      },
      "source": [
        "También se carga la función para preprocesar el texto que se usó en los otros modelos desde el repo: https://github.com/jumafernandez/clasificacion_correos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0o2NndLWDVC"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_preprocesamiento.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_preprocesamiento.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_preprocesamiento import preprocesar_correos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv6R5UQWWmE"
      },
      "source": [
        "### Carga de datos\n",
        "\n",
        "Se carga el dataframe en memoria con el preprocesamiento de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "7df1ca99-0bcf-4507-9d2b-f506c4659fd2"
      },
      "source": [
        "import warnings\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Constantes con los datos\n",
        "DS_DIR = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/'\n",
        "TRAIN_FILE = 'correos-train-80.csv'\n",
        "TEST_FILE = 'correos-test-20.csv'\n",
        "\n",
        "# Chequeo sobre si los archivos están en el working directory\n",
        "download_files = not(path.exists(TRAIN_FILE))\n",
        "\n",
        "etiquetas = get_clases()\n",
        "\n",
        "# Defino la cantidad de clases a utilizar (todas para este experimento)\n",
        "CANTIDAD_CLASES = len(etiquetas)\n",
        "\n",
        "train_df, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "# Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "import pandas as pd\n",
        "train_df['Consulta'] = pd.Series(preprocesar_correos(train_df['Consulta']))\n",
        "test_df['Consulta'] = pd.Series(preprocesar_correos(test_df['Consulta']))\n",
        "\n",
        "# Cambio los integers por las etiquetas\n",
        "train_df['clase'] = etiquetas[train_df['clase']]\n",
        "test_df['clase'] = etiquetas[test_df['clase']]\n",
        "\n",
        "# Muestro salida por consola\n",
        "print('Existen {} clases: {}.'.format(len(train_df.clase.unique()), train_df.clase.unique()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se inicia descarga de los datasets.\n",
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (800, 24)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 20 clases: ['Inscripción a Cursadas' 'Cambio de Carrera' 'Reincorporación'\n",
            " 'Ingreso a la Universidad' 'Boleto Universitario'\n",
            " 'Pedido de Certificados' 'Exámenes' 'Requisitos de Ingreso' 'Cursadas'\n",
            " 'Situación Académica' 'Vacunas Enfermería' 'Consulta por Legajo'\n",
            " 'Problemas con la Clave' 'Consulta sobre Título Universitario'\n",
            " 'Certificados Web' 'Carga de Notas' 'Otras Consultas'\n",
            " 'Cambio de Comisión' 'Consulta por Equivalencias' 'Datos Personales'].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Se carga en memoria la función _grid_search_por_estrategia_representacion_ que va a iterar ajustando los hiperparámetros para las técnica de __SVM__:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XF6H0BGX9F9"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_clasificacion_texto.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_clasificacion_texto.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_clasificacion_texto import gridsearch_por_estrategia_representacion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiAo2N8TX-ao"
      },
      "source": [
        "Se define el espacio de búsqueda para el ajuste de hiperparámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TOc1GcX-rg"
      },
      "source": [
        "# Defino una lista con los esquemas de representación\n",
        "estrategias_representacion = ['BASELINE', 'BOW', 'TFIDF', '3-4-NGRAM-CHARS', '1-2-NGRAM-WORDS']\n",
        "modelo = 'SVM'\n",
        "\n",
        "# Defino los parámetros para GridSearchCV\n",
        "params_svm = {'SVM__C': [0.01, 0.1, 1, 10, 100, 1000], \n",
        "              'SVM__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'SVM__class_weight': [None, 'balanced'],\n",
        "              'SVM__kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "              }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnm8yPmYGAR"
      },
      "source": [
        "Se ejecuta el ajuste de hiperparámetros para cada estrategia de representación en función del espacio de búsqueda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSOquuAYGPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a20f684-83c5-49da-d90f-2423828c970b"
      },
      "source": [
        "for estrategia in estrategias_representacion:\n",
        "  # Llamo a la función que realiza el gridsearch por estrategia  \n",
        "  gridsearch_por_estrategia_representacion(train_df, test_df, estrategia, modelo, params_svm, 'drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estrategia de representación: BASELINE\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   49.3s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 24.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 34.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 35.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n",
            "Estrategia de representación: BASELINE\n",
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 1, 'SVM__kernel': 'linear', 'clasificador': 'SVM', 'estrategia': 'BASELINE', 'accuracy': 0.74, 'precision': 0.45766689158794416, 'recall': 0.4497441905021692, 'f1_score': 0.44116639494792065}\n",
            "Accuracy Test-Set: 0.74\n",
            "Estrategia de representación: BOW\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   49.6s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 24.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 34.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 36.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: BOW\n",
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 1, 'SVM__kernel': 'linear', 'clasificador': 'SVM', 'estrategia': 'BOW', 'accuracy': 0.74, 'precision': 0.45766689158794416, 'recall': 0.4497441905021692, 'f1_score': 0.44116639494792065}\n",
            "Accuracy Test-Set: 0.74\n",
            "Estrategia de representación: TFIDF\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   49.8s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 15.8min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 25.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 37.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: TFIDF\n",
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 1, 'SVM__kernel': 'linear', 'clasificador': 'SVM', 'estrategia': 'TFIDF', 'accuracy': 0.735, 'precision': 0.427054983283636, 'recall': 0.3820756371288286, 'f1_score': 0.37691188828921673}\n",
            "Accuracy Test-Set: 0.735\n",
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 17.7min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 45.8min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 83.8min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 134.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 192.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 201.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Parámetros: {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'clasificador': 'SVM', 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.74, 'precision': 0.46607183292897575, 'recall': 0.45074162834801135, 'f1_score': 0.44850422387917066}\n",
            "Accuracy Test-Set: 0.74\n",
            "Estrategia de representación: 1-2-NGRAM-WORDS\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  4.7min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "# Referencias\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}