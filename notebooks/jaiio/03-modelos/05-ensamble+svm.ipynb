{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-ensamble+svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jaiio/03-modelos/05-ensamble%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Sistema de votación (LR+SS3+TFIDF) + SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos a partir de los datos etiquetados automáticamente a partir de las _features_ extraidas del train dataset con todas las estrategias + la construcción de un clasificador con SVM.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC29-nnEqmXI"
      },
      "source": [
        "## 0. Configuración de la ejecución\n",
        "\n",
        "A continuación se genera la configuración de las estrategias que integrarán el sistema de votación para la obtención de instancias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLm7kOaOrIGs"
      },
      "source": [
        "# Posibilidades : lr, ss3, tfidf\n",
        "# Combinaciones:\n",
        "# lr-ss3\n",
        "# lr-tfidf\n",
        "# ss3-tfidf\n",
        "# lr-ss3-tfidf\n",
        "estrategias_feature_extraction = ['ss3']\n",
        "\n",
        "# Se define si se incorporan las instancias definidas manualmente\n",
        "ACUMULATIVO = True\n",
        "\n",
        "# Para el sistema de votación queda fijo\n",
        "CANTIDAD_INSTANCIAS = 100\n",
        "\n",
        "# Defino una lista con los esquemas de representación y la cantidad de tokens\n",
        "estrategias_representacion = ['BINARIO', 'TFIDF', '3-4-NGRAM-CHARS', '1-2-NGRAM-WORDS']\n",
        "estrategias_representacion = ['1-2-NGRAM-WORDS']\n",
        "ATRIBUTOS_DINAMICOS = 3000\n",
        "\n",
        "# Defino la técnica de ML\n",
        "tecnica = 'SVM'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4Zpxhs3OKR"
      },
      "source": [
        "Se definen algunas características fijas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2FEE93duakY"
      },
      "source": [
        "# El archivo de test y el train con etiquetado manual es siempre el mismo\n",
        "TEST_FILE = 'correos-test-jaiio-20.csv'\n",
        "TRAIN_FILE_MANUAL = 'correos-train-jaiio-80.csv'\n",
        "atributos_df = ['consulta', 'dia_semana', 'semana_del_mes', 'mes', 'cuatrimestre',\n",
        "                  'anio', 'hora_discretizada', 'dni_discretizado', 'legajo_discretizado',\n",
        "                  'posee_legajo', 'posee_telefono', 'carrera_valor', 'proveedor_correo',\n",
        "                  'cantidad_caracteres', 'proporcion_mayusculas', 'proporcion_letras',\n",
        "                  'cantidad_tildes', 'cantidad_palabras', 'cantidad_palabras_cortas',\n",
        "                  'proporcion_palabras_distintas', 'frecuencia_signos_puntuacion',\n",
        "                  'cantidad_oraciones', 'utiliza_codigo_asignatura', 'score', 'clase_e0']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnCRBjnD3SBJ"
      },
      "source": [
        "Y se generan los datos en función de la cantidad de estrategias a utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kOC3LVy3SPT",
        "outputId": "7e3e6abb-e798-435d-8d3b-fab8a16cfd4f"
      },
      "source": [
        "# Se genera el nombre del archivo de instancias a ejecutar en función de las estrategias\n",
        "TRAIN_FILE_E0 = f'dataset-{estrategias_feature_extraction[0]}-200-prep.csv'\n",
        "texto = f'Los dataset a utilizar son: \\n\\t{TRAIN_FILE_E0}'\n",
        "\n",
        "# En caso que se realice el ensamble entre las 2 estrategias\n",
        "if len(estrategias_feature_extraction)>=2:\n",
        "  TRAIN_FILE_E1 = f'dataset-{estrategias_feature_extraction[1]}-200-prep.csv'\n",
        "  texto = texto + f'\\n\\t{TRAIN_FILE_E1}'\n",
        "  # Se define el if para que ante reiteradas ejecuciones de la notebook no se vuelva a insertar\n",
        "  if 'clase_e1' not in atributos_df:\n",
        "    atributos_df.append('clase_e1')\n",
        "\n",
        "# En caso que se realice el ensamble entre las 3 estrategias\n",
        "if len(estrategias_feature_extraction)==3:\n",
        "  TRAIN_FILE_E2 = f'dataset-{estrategias_feature_extraction[2]}-200-prep.csv'\n",
        "  texto = texto + f'\\n\\t{TRAIN_FILE_E2}' \n",
        "  # Se define el if para que ante reiteradas ejecuciones de la notebook no se vuelva a insertar\n",
        "  if 'clase_e2' not in atributos_df:\n",
        "    atributos_df.append('clase_e2')\n",
        "\n",
        "print(texto)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los dataset a utilizar son: \n",
            "\tdataset-ss3-200-prep.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLanwDJVnFF"
      },
      "source": [
        "## 1. Instalación y Carga de librerías y funciones útiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-dNi6mDUZnb"
      },
      "source": [
        "### 1.1 Instalación de librerías\n",
        "\n",
        "Se instalan las librerías que no están en el entorno de Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644uDER_VnXj",
        "outputId": "e491dd89-fc0d-4904-b773-e461c36fa71b"
      },
      "source": [
        "# Se instala gensim que es el que tiene el modelo Word2Vec\n",
        "!pip install requests\n",
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fDuhK2V1kx"
      },
      "source": [
        "### 1.2 Funciones útiles\n",
        "\n",
        "Se cargan funciones útiles desde el repo https://github.com/jumafernandez/clasificacion_correos para la carga y balanceo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_dataset.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_dataset.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_dataset import get_clases, cargar_dataset, consolidar_df, generar_train_test_set"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxjaGIfV-rT"
      },
      "source": [
        "También se carga la función para preprocesar el texto que se usó en los otros modelos desde el repo: https://github.com/jumafernandez/clasificacion_correos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0o2NndLWDVC"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_preprocesamiento.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_preprocesamiento.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_preprocesamiento import preprocesar_correos"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOOwBxoYUoWC"
      },
      "source": [
        "### 1.2.1. Carga de librerías de procesamiento de texto\n",
        "\n",
        "Se cargan en memoria dos funciones: _grid_search_por_estrategia_representacion_ que va a iterar ajustando los hiperparámetros para las técnica de __SVM__ y _representacion_documentos_ que genera representaciones para las _features textuales_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XF6H0BGX9F9"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_clasificacion_texto.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_clasificacion_texto.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_clasificacion_texto import gridsearch_por_estrategia_representacion, representacion_documentos, gridsearch_por_tecnica"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv6R5UQWWmE"
      },
      "source": [
        "### 1.3. Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdGnbPiUk-mS"
      },
      "source": [
        "Cargo la librería warnings para no mostrar las advertencias, pandas para el manejo de df y os para verificar la existencia de los archivos en la carga de datos. Además, cargo en memoria la URL de base de los datasets y una lista de las etiquetas de las distintas clases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TsEFWTAk_qc"
      },
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Constantes con los datos\n",
        "DS_DIR = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/50jaiio/consolidados/'\n",
        "\n",
        "# Defino las clases y la cantidad a utilizar\n",
        "etiquetas = get_clases()\n",
        "CANTIDAD_CLASES = len(etiquetas)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuWVxIdck-v5"
      },
      "source": [
        "Se cargan los dataframes de las estrategias seleccionadas en memoria con el preprocesamiento de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "235833ac-3ae7-4df4-d431-e4cd8ea5d98f"
      },
      "source": [
        "# Chequeo sobre si los archivos están en el working directory\n",
        "download_files = not(path.exists(TRAIN_FILE_E0))\n",
        "\n",
        "df_e0, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E0, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "# Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "df_e0['consulta'] = pd.Series(preprocesar_correos(df_e0['consulta']))\n",
        "test_df['consulta'] = pd.Series(preprocesar_correos(test_df['consulta']))\n",
        "\n",
        "# Muestro salida por consola\n",
        "print('Existen {} clases: {}.'.format(len(df_e0.clase.unique()), df_e0.clase.unique()))\n",
        "\n",
        "# Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "if CANTIDAD_INSTANCIAS<200:\n",
        "  df_e0 = df_e0.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "  df_e0 = df_e0.sample(frac = 1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se inicia descarga de los datasets.\n",
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (3200, 25)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Cambio de Carrera' 'Cambio de Comisión'\n",
            " 'Consulta por Equivalencias' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Cursadas' 'Datos Personales'\n",
            " 'Exámenes' 'Ingreso a la Universidad' 'Pedido de Certificados'\n",
            " 'Problemas con la Clave' 'Reincorporación' 'Requisitos de Ingreso'\n",
            " 'Simultaneidad de Carreras' 'Situación Académica'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BPhRHNBSYUW"
      },
      "source": [
        "if len(estrategias_feature_extraction)>=2:\n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_E1))\n",
        "\n",
        "  df_e1, test_df_e1, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E1, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "  df_e1['consulta'] = pd.Series(preprocesar_correos(df_e1['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(df_e1.clase.unique()), df_e1.clase.unique()))\n",
        "\n",
        "  # Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "  if CANTIDAD_INSTANCIAS<200:\n",
        "    df_e1 = df_e1.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "    df_e1 = df_e1.sample(frac = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOJGQpwSkqCw"
      },
      "source": [
        "Solo en el caso que decida hacer el sistema de votación entre las 3 estrategias inicializo la tercera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4OziqC3WjET"
      },
      "source": [
        "if len(estrategias_feature_extraction)==3:\n",
        "\n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_E2))\n",
        "\n",
        "  df_e2, test_df_e2, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E2, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "  df_e2['consulta'] = pd.Series(preprocesar_correos(df_e2['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(df_e2.clase.unique()), df_e2.clase.unique()))\n",
        "\n",
        "  # Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "  if CANTIDAD_INSTANCIAS<200:\n",
        "    df_e2 = df_e2.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "    df_e2 = df_e2.sample(frac = 1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD6F7H8Co80F"
      },
      "source": [
        "Verifico si voy a acumular los datos etiquetados manualmente a los de etiquetado no supervisado y en caso afirmativo los cargo en memoria:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjGj575EAKm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9cc088-114d-490a-fcca-d2084526c190"
      },
      "source": [
        "if ACUMULATIVO:\n",
        " \n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_MANUAL))\n",
        "\n",
        "  train_df_manual, test_df_manual, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_MANUAL, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "  train_df_manual['consulta'] = pd.Series(preprocesar_correos(train_df_manual['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(train_df_manual.clase.unique()), train_df_manual.clase.unique()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (800, 24)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Problemas con la Clave' 'Cursadas'\n",
            " 'Cambio de Carrera' 'Ingreso a la Universidad' 'Requisitos de Ingreso'\n",
            " 'Reincorporación' 'Pedido de Certificados' 'Situación Académica'\n",
            " 'Exámenes' 'Cambio de Comisión' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Datos Personales'\n",
            " 'Consulta por Equivalencias' 'Simultaneidad de Carreras'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RXDYdtTsl31"
      },
      "source": [
        "### 1.4 Sistema de votación entre estrategias de _feature extraction_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfXzjTUVpIzM"
      },
      "source": [
        "En primer lugar, se joinea mediante el texto de la consulta las estrategias encaradas (según sean dos o tres):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtsZgzmTZPyG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Si se utiliza sólo 1 estrategia, se inicializa el df_join con solo esa\n",
        "if len(estrategias_feature_extraction)==1:\n",
        "  df_join = df_e0\n",
        "\n",
        "# Si se utilizan al menos 2 estrategias, se incorpora también la 2da\n",
        "if len(estrategias_feature_extraction)>=2:\n",
        "  df_join = pd.merge(df_e0, df_e1, on='consulta', how='left', suffixes=(None, \"_x\"))\n",
        "\n",
        "# Si están las 3 estrategias, se incorpora también la 3era\n",
        "if len(estrategias_feature_extraction)==3:\n",
        "  df_join = pd.merge(df_join, df_e2, on='consulta', how='left', suffixes=(None, \"_y\"))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMv6W-y4MbJ"
      },
      "source": [
        "Borro las instancias con faltantes y verifico el resultado la dimensionalidad del df:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA6GiR72ZaGi",
        "outputId": "72f1cd3a-f573-496b-f250-5487d5209d3b"
      },
      "source": [
        "df_join = df_join.dropna()\n",
        "\n",
        "df_join.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "GtNhv0fJvq2S",
        "outputId": "31711bdd-b334-4eff-a078-f887d3cf5077"
      },
      "source": [
        "df_join.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consulta</th>\n",
              "      <th>dia_semana</th>\n",
              "      <th>semana_del_mes</th>\n",
              "      <th>mes</th>\n",
              "      <th>cuatrimestre</th>\n",
              "      <th>anio</th>\n",
              "      <th>hora_discretizada</th>\n",
              "      <th>dni_discretizado</th>\n",
              "      <th>legajo_discretizado</th>\n",
              "      <th>posee_legajo</th>\n",
              "      <th>posee_telefono</th>\n",
              "      <th>carrera_valor</th>\n",
              "      <th>proveedor_correo</th>\n",
              "      <th>cantidad_caracteres</th>\n",
              "      <th>proporcion_mayusculas</th>\n",
              "      <th>proporcion_letras</th>\n",
              "      <th>cantidad_tildes</th>\n",
              "      <th>cantidad_palabras</th>\n",
              "      <th>cantidad_palabras_cortas</th>\n",
              "      <th>proporcion_palabras_distintas</th>\n",
              "      <th>frecuencia_signos_puntuacion</th>\n",
              "      <th>cantidad_oraciones</th>\n",
              "      <th>utiliza_codigo_asignatura</th>\n",
              "      <th>score</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>buenas noches realizar solicitud inscripcion v...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.786260</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>0.015267</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.039520</td>\n",
              "      <td>Datos Personales</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>hola queria saber figuro deje figurar alumno r...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783951</td>\n",
              "      <td>2</td>\n",
              "      <td>31</td>\n",
              "      <td>18</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.006173</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>21.308723</td>\n",
              "      <td>Reincorporación</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1574</th>\n",
              "      <td>buenas tardes queria consultar responda acredi...</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>22</td>\n",
              "      <td>285</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.775439</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>33</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.021053</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27.116535</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hola buenas tardes consulta calificacion segun...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>22</td>\n",
              "      <td>302</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784768</td>\n",
              "      <td>6</td>\n",
              "      <td>57</td>\n",
              "      <td>33</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.023179</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>22.453770</td>\n",
              "      <td>Situación Académica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>buenos dias quisiera tramitar titulo da opcion...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>212</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.797170</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>19</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.033019</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>20.836270</td>\n",
              "      <td>Consulta sobre Título Universitario</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               consulta  ...                                clase\n",
              "858   buenas noches realizar solicitud inscripcion v...  ...                     Datos Personales\n",
              "301   hola queria saber figuro deje figurar alumno r...  ...                      Reincorporación\n",
              "1574  buenas tardes queria consultar responda acredi...  ...                 Boleto Universitario\n",
              "6     hola buenas tardes consulta calificacion segun...  ...                  Situación Académica\n",
              "1030  buenos dias quisiera tramitar titulo da opcion...  ...  Consulta sobre Título Universitario\n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKK_XeCr4m59"
      },
      "source": [
        "Renombro las clases en función de las estrategias y me quedo sólo con las instancias en que la clase coincide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfUF6_C4i2E",
        "outputId": "c4a37e37-9d0b-4288-caa8-594bf7854b54"
      },
      "source": [
        "if len(estrategias_feature_extraction)==3:\n",
        "  df_join.rename(columns={'clase_x': 'clase_e0', 'clase_y': 'clase_e1', 'clase': 'clase_e2'}, inplace=True)\n",
        "  df_join['match_clase'] = ((df_join['clase_e0'] == df_join['clase_e1']) & (df_join['clase_e1'] == df_join['clase_e2']))\n",
        "elif len(estrategias_feature_extraction)==2:\n",
        "  df_join.rename(columns={'clase': 'clase_e0', 'clase_x': 'clase_e1'}, inplace=True)\n",
        "  df_join['match_clase'] = df_join['clase_e0'] == df_join['clase_e1']\n",
        "elif len(estrategias_feature_extraction)==1:\n",
        "  df_join.rename(columns={'clase': 'clase_e0'}, inplace=True)\n",
        "  # Esto se hace por compatibilidad con las otras alternativas (2 y 3 estrategias)\n",
        "  df_join['match_clase'] = df_join['clase_e0'] == df_join['clase_e0']\n",
        " \n",
        "# Me quedo sólo con las instancias en que la clase coincide\n",
        "train_df_join = df_join.query('match_clase == True').reset_index()\n",
        "\n",
        "train_df_join.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phy2ZVCl4KoT"
      },
      "source": [
        "Me quedo solo con los atributos que me interesan (elimino duplicados):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieGYeC6q4K0B",
        "outputId": "e44d5a76-337a-474c-e8f6-ffd45979ea0d"
      },
      "source": [
        "train_df_join = train_df_join[atributos_df]\n",
        "\n",
        "train_df_join.columns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['consulta', 'dia_semana', 'semana_del_mes', 'mes', 'cuatrimestre',\n",
              "       'anio', 'hora_discretizada', 'dni_discretizado', 'legajo_discretizado',\n",
              "       'posee_legajo', 'posee_telefono', 'carrera_valor', 'proveedor_correo',\n",
              "       'cantidad_caracteres', 'proporcion_mayusculas', 'proporcion_letras',\n",
              "       'cantidad_tildes', 'cantidad_palabras', 'cantidad_palabras_cortas',\n",
              "       'proporcion_palabras_distintas', 'frecuencia_signos_puntuacion',\n",
              "       'cantidad_oraciones', 'utiliza_codigo_asignatura', 'score', 'clase_e0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-e0IcaYnf8f"
      },
      "source": [
        "Me quedo sólo con una columna de clase dado que son las 3 iguales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oezp0Fvk7QT",
        "outputId": "a70b499d-6d6e-4e64-c4e5-063b6df2073a"
      },
      "source": [
        "# Tomo una clase al azar, dado que coinciden las 3\n",
        "train_df_join.rename(columns={'clase_e0': 'clase'}, inplace=True)\n",
        "\n",
        "# Elimino las columnas que no necesito\n",
        "if len(estrategias_feature_extraction)>=2:\n",
        "  train_df_join.drop(['clase_e1'], inplace=True, axis=1)\n",
        "\n",
        "if len(estrategias_feature_extraction)==3:\n",
        "  train_df_join.drop(['clase_e2'], inplace=True, axis=1)\n",
        "\n",
        "train_df_join.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IKK2WwlVLye"
      },
      "source": [
        "Me guardo la columna del score de Elasticsearch para no generar incompatibilidades:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daumQbloVLNa"
      },
      "source": [
        "score = train_df_join['score']\n",
        "train_df_join.drop('score', inplace=True, axis=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_WMVnGCAt66"
      },
      "source": [
        "if ACUMULATIVO:\n",
        "  train_df = pd.concat([train_df_manual, train_df_join], axis=0).reset_index(drop=True)\n",
        "else:\n",
        "  train_df = train_df_join"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qdJuRmxoaXV"
      },
      "source": [
        "Muestro el dataframe resultante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z_-PYK9nU_7",
        "outputId": "74a9ca26-34e1-45e2-bbd7-4cabf526a680"
      },
      "source": [
        "# pd.set_option('display.max_colwidth', None)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "train_df.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJHaVhO8ZpRx",
        "outputId": "3f80478d-bd78-4bb4-f7c1-cbf878492506"
      },
      "source": [
        "X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, '3-4-NGRAM-CHARS', MAX_TKS=ATRIBUTOS_DINAMICOS)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrategia de representación: 3-4-NGRAM-CHARS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndyqr3kmakbB",
        "outputId": "e4e716bc-8c64-40fd-adaf-1ce786c05152"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 3022)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## 2. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6VPw5NNYje"
      },
      "source": [
        "### 2.1 Modelo general (clasificación en las 16 clases)\n",
        "\n",
        "En primer lugar se trabaja con un único clasificador que clasifica y testea las instancias en las 16 clases posibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgPWXtpU_7v"
      },
      "source": [
        "#### 2.1.1 Definición del espacio de búsqueda\n",
        "\n",
        "Se define el espacio de búsqueda para el ajuste de hiperparámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TOc1GcX-rg"
      },
      "source": [
        "# Defino los parámetros para GridSearchCV\n",
        "params_svm = {'SVM__C': [0.1, 1, 10], \n",
        "              'SVM__gamma': [0.01, 0.1, 1],\n",
        "              'SVM__class_weight': [None, 'balanced'],\n",
        "              'SVM__kernel': ['rbf', 'linear', 'sigmoid'],\n",
        "              'SVM__probability': [False]\n",
        "              }"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnm8yPmYGAR"
      },
      "source": [
        "Se ejecuta el ajuste de hiperparámetros para cada estrategia de representación en función del espacio de búsqueda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSOquuAYGPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90715307-6676-49f4-e6f3-8fdc3a65e089"
      },
      "source": [
        "modelos_grid = []\n",
        "representacion_grid = []\n",
        "metricas_grid = []\n",
        "NO_CORRIDA = True\n",
        "\n",
        "# Modulo para la hora (a efectos de calcular los tiempos de ejecución)\n",
        "import time\n",
        "\n",
        "if NO_CORRIDA:\n",
        "  # Se hace una búsqueda grid por estrategia de representación\n",
        "  for estrategia in estrategias_representacion:\n",
        "    \n",
        "    # Generamos los datos de train y test por estrategia\n",
        "    X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, estrategia, MAX_TKS=ATRIBUTOS_DINAMICOS)\n",
        "\n",
        "    # Se imprime la hora local\n",
        "    print(f'Hora de inicio de la búsqueda grid: {time.strftime('%H:%M:%S, %Y-%m-%d ', time.localtime())}.')\n",
        "\n",
        "    # Llamo a la función que realiza el gridsearch por estrategia  \n",
        "    clf_grid, metrics_grid = gridsearch_por_tecnica(X_train, y_train, X_test, y_test, tecnica, params_svm)\n",
        "\n",
        "    # Guardamos el mejor modelo para cada estrategia de representación\n",
        "    modelos_grid.append(clf_grid)\n",
        "    representacion_grid.append(estrategia)\n",
        "    metricas_grid.append(metrics_grid)\n",
        "\n",
        "# ['lr', 'tfidf']\n",
        "# Métricas sobre Test-Set: {'SVM__C': 10, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': 'BINARIO', 'accuracy': 0.795, 'precision': 0.7967703533026114, 'recall': 0.795, 'f1_score': 0.789165448506101}\n",
        "# Métricas sobre Test-Set:    {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': 'TFIDF', 'accuracy': 0.78, 'precision': 0.8076557773744707, 'recall': 0.78, 'f1_score': 0.788321119391772}\n",
        "#  Métricas sobre Test-Set: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'clasificador': 'SVM', 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.835, 'precision': 0.866807546108862, 'recall': 0.835, 'f1_score': 0.842616215602101}\n",
        "# Parámetros: {'SVM__C': 0.1, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'linear', 'SVM__probability': False}\n",
        "# Métricas sobre Test-Set: {'accuracy': 0.855, 'precision': 0.8685175150519977, 'recall': 0.855, 'f1_score': 0.8574449514612386, 'mcc': 0.8341688372038628}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estrategia de representación: BINARIO\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 30.8min\n",
            "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 61.1min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': None, 'SVM__gamma': 0.1, 'SVM__kernel': 'sigmoid', 'SVM__probability': False}\n",
            "Accuracy Test-Set: 0.795\n",
            "Métricas sobre Test-Set: {'accuracy': 0.795, 'precision': 0.8227500000000001, 'recall': 0.795, 'f1_score': 0.8011273367417096, 'mcc': 0.7654534141356333}\n",
            "Estrategia de representación: TFIDF\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 34.3min\n",
            "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 71.2min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros: {'SVM__C': 10, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'SVM__probability': False}\n",
            "Accuracy Test-Set: 0.815\n",
            "Métricas sobre Test-Set: {'accuracy': 0.815, 'precision': 0.8578071428571428, 'recall': 0.815, 'f1_score': 0.8271000643672002, 'mcc': 0.7900484929146843}\n",
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 30.6min\n",
            "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 62.0min finished\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'SVM__probability': False}\n",
            "Accuracy Test-Set: 0.765\n",
            "Métricas sobre Test-Set: {'accuracy': 0.765, 'precision': 0.8489852240896358, 'recall': 0.765, 'f1_score': 0.7934865816983557, 'mcc': 0.7363091622085939}\n",
            "Estrategia de representación: 1-2-NGRAM-WORDS\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  8.0min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BLl1MGrOdXs"
      },
      "source": [
        "A partir de los mejores hiperparámetros encontrados para cada estrategia de representación de correos, se busca cual es la estrategia que generó el mayor _accuracy_ (medida totalmente arbitraria):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZPszyNuh1d"
      },
      "source": [
        "max_accuracy = 0\n",
        "for i in range(1, len(metricas_grid)):\n",
        "  if metricas_grid[i]['accuracy'] > metricas_grid[max_accuracy]['accuracy']:\n",
        "    max_accuracy = i\n",
        "\n",
        "representacion_max = representacion_grid[max_accuracy]\n",
        "\n",
        "# Se le quita el prefijo asignado a los parametricos para la búsqueda grid\n",
        "params_max = params = {x.replace(\"SVM__\", \"\"): v for x, v in modelos_grid[max_accuracy].best_params_.items()}\n",
        "\n",
        "metricas_max = metricas_grid[max_accuracy]\n",
        "\n",
        "print(f'Sistema de generación de instancias: {estrategias_feature_extraction}', sep=\"\")\n",
        "if ACUMULATIVO:\n",
        "  print(f'Las instancias se ACUMULAN a las etiquetadas manualmente')\n",
        "else:\n",
        "  print(f'Las instancias NO SE ACUMULAN a las etiquetadas manualmente')\n",
        "\n",
        "print(f'El modelo más eficaz es {tecnica} con la estrategia de representación {representacion_max} y los parámetros:\\n {params_max}')\n",
        "print(f'El modelo brinda las siguientes métricas de selección:\\n {metricas_max}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjoUvaOgh00W"
      },
      "source": [
        "#### 2.1.2 Modelo generado\n",
        "\n",
        "En función de los mejores hiperparámetros y estrategia de representación encontrados con la búsqueda Grid, ajusto el modelo para obtener las métricas.\n",
        "\n",
        "En primer lugar genero los datos de train y test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfU5JT1vh0J3"
      },
      "source": [
        "# Mejores Parámetros según GridSearchCV:\n",
        "# {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'estrategia': '3-4-NGRAM-CHARS', \n",
        "#  'accuracy': 0.81, 'precision': 0.5971321956813028, 'recall': 0.553190280233687, 'f1_score': 0.5639032258154839}\n",
        "# Métricas sobre Test-Set: {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'SVM__probability': True, 'clasificador': 'SVM',\n",
        "# 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.835, 'precision': 0.8428499293134182, 'recall': 0.835, 'f1_score': 0.8328323317634259}\n",
        "\n",
        "X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, representacion_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBgo7dzPLkv5"
      },
      "source": [
        "Se entrena el modelo con los mejores hiperparámetros encontrados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXrnHa4qH8in"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC(**params_max)\n",
        "\n",
        "# Entreno el modelo con los parámetros\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzVZFzCTVTSZ"
      },
      "source": [
        "Se predicen las instancias de testeo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNoj8Gshc09R"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIpzEIaOWKNa"
      },
      "source": [
        "#### 2.1.3 Métricas de selección"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-THNpdciSP"
      },
      "source": [
        "from sklearn import metrics #Importar el módulo metrics de scikit-learn\n",
        "\n",
        "# Vamos a testear el modelo\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Vemos un reporte de clasificación de varias métricas\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8dTwLl5dYu-"
      },
      "source": [
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYUVKbHldjKq"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mat = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "\n",
        "plt.xlabel('Observada')\n",
        "plt.ylabel('Predicha');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P14cduVB6pZk"
      },
      "source": [
        "### 3. Análisis del error\n",
        "\n",
        "A continuación se intenta entender la baja de _accuracy_ para el etiquetado a partir de TF-IDF.\n",
        "\n",
        "Para ello, se genera el dataset de train con: <br/>\n",
        "| consulta | clase | score |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yzf0qf36oL2"
      },
      "source": [
        "df_train_e = train_df[['consulta', 'clase']]\n",
        "df_train_e['score'] = score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJVVj9Kk6uhd"
      },
      "source": [
        "Genero un dataframe con los scores promedios por clase, el accuracy por clase y el _count_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRdVnXSN6wkJ"
      },
      "source": [
        "df_error = df_train_e.groupby(['clase']).mean().reset_index()\n",
        "# Accuracy por clase\n",
        "avg_class = mat.diagonal()/mat.sum(axis=1)\n",
        "df_error['accuracy'] = pd.Series(avg_class)\n",
        "\n",
        "df_error['count'] = mat.sum(axis=1)\n",
        "\n",
        "df_error\n",
        "df_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRKtSNPr63Oo"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "sns.scatterplot(data=df_error, x=\"score\", y=\"accuracy\", hue=\"count\", size=\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "## Referencias\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}