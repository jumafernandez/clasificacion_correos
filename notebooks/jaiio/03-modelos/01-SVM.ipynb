{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jaiio/03-modelos/01-SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Combinaciones de estrategias de etiquetado + SVM\n",
        "\n",
        "En esta notebook se presentan los experimentos a partir de los datos etiquetados manualmente junto con los automáticos a partir de las features extraidas del train dataset con todas las combinaciones de estrategias de selección de características + las combinaciones de estrategias de representación de documentos (pesados binario y tf-idf, 3-4-gramas de caracteres y 1-2-gramas de palabras) + la construcción de un clasificador con SVM (máquinas vector soporte)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC29-nnEqmXI"
      },
      "source": [
        "## 0. Configuración de la ejecución\n",
        "\n",
        "A continuación se genera la configuración de las estrategias que integrarán el sistema de votación para la obtención de instancias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLm7kOaOrIGs"
      },
      "source": [
        "# Posibilidades : lr, ss3, tfidf\n",
        "# Combinaciones:\n",
        "# lr-ss3\n",
        "# lr-tfidf\n",
        "# ss3-tfidf\n",
        "# lr-ss3-tfidf\n",
        "estrategias_feature_extraction = ['tfidf', 'ss3', 'lr']\n",
        "\n",
        "# Se define si se incorporan las instancias definidas manualmente\n",
        "ETIQUETADO_MANUAL = False\n",
        "\n",
        "# Para el sistema de votación queda fija la cantidad de instancias\n",
        "CANTIDAD_INSTANCIAS = 200\n",
        "BOOSTING = False\n",
        "\n",
        "# Defino una lista con los esquemas de representación y la cantidad de tokens\n",
        "estrategias_representacion = ['BINARIO', 'TFIDF', '3-4-NGRAM-CHARS', '1-2-NGRAM-WORDS']\n",
        "ATRIBUTOS_DINAMICOS = 3000\n",
        "\n",
        "# Defino la técnica de ML\n",
        "tecnica = 'SVM'"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4Zpxhs3OKR"
      },
      "source": [
        "Se definen algunas características fijas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2FEE93duakY"
      },
      "source": [
        "# El archivo de test y el train con etiquetado manual es siempre el mismo\n",
        "TRAIN_FILE_MANUAL = 'correos-train-jaiio-80.csv'\n",
        "TEST_FILE = 'correos-test-jaiio-20.csv'\n",
        "atributos_df = ['consulta', 'dia_semana', 'semana_del_mes', 'mes', 'cuatrimestre',\n",
        "                  'anio', 'hora_discretizada', 'dni_discretizado', 'legajo_discretizado',\n",
        "                  'posee_legajo', 'posee_telefono', 'carrera_valor', 'proveedor_correo',\n",
        "                  'cantidad_caracteres', 'proporcion_mayusculas', 'proporcion_letras',\n",
        "                  'cantidad_tildes', 'cantidad_palabras', 'cantidad_palabras_cortas',\n",
        "                  'proporcion_palabras_distintas', 'frecuencia_signos_puntuacion',\n",
        "                  'cantidad_oraciones', 'utiliza_codigo_asignatura', 'score']"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnCRBjnD3SBJ"
      },
      "source": [
        "Y se generan los datos en función de la cantidad de estrategias a utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kOC3LVy3SPT",
        "outputId": "0fb64c77-e466-4bbc-e97d-49abf00484f2"
      },
      "source": [
        "# Se genera el nombre del archivo de instancias a ejecutar en función de las estrategias\n",
        "\n",
        "# En caso que se realice el ensamble entre las n estrategias\n",
        "if len(estrategias_feature_extraction)>=1:\n",
        "  if BOOSTING:\n",
        "    TRAIN_FILE_E0 = f'dataset-{estrategias_feature_extraction[0]}-200-boosting-prep.csv'\n",
        "  else:\n",
        "    TRAIN_FILE_E0 = f'dataset-{estrategias_feature_extraction[0]}-200-prep.csv'\n",
        "  texto = f'Los dataset a utilizar son: \\n\\t{TRAIN_FILE_E0}'\n",
        "  # Se define el if para que ante reiteradas ejecuciones de la notebook no se vuelva a insertar\n",
        "  if 'clase_e0' not in atributos_df:\n",
        "    atributos_df.append('clase_e0')\n",
        "\n",
        "if len(estrategias_feature_extraction)>=2:\n",
        "  if BOOSTING:\n",
        "    TRAIN_FILE_E1 = f'dataset-{estrategias_feature_extraction[1]}-200-boosting-prep.csv'\n",
        "  else:\n",
        "    TRAIN_FILE_E1 = f'dataset-{estrategias_feature_extraction[1]}-200-prep.csv'\n",
        "  texto = texto + f'\\n\\t{TRAIN_FILE_E1}'\n",
        "  # Se define el if para que ante reiteradas ejecuciones de la notebook no se vuelva a insertar\n",
        "  if 'clase_e1' not in atributos_df:\n",
        "    atributos_df.append('clase_e1')\n",
        "\n",
        "# En caso que se realice el ensamble entre las 3 estrategias\n",
        "if len(estrategias_feature_extraction)==3:\n",
        "  if BOOSTING:\n",
        "    TRAIN_FILE_E2 = f'dataset-{estrategias_feature_extraction[2]}-200-boosting-prep.csv'\n",
        "  else:\n",
        "    TRAIN_FILE_E2 = f'dataset-{estrategias_feature_extraction[2]}-200-prep.csv'\n",
        "\n",
        "  texto = texto + f'\\n\\t{TRAIN_FILE_E2}' \n",
        "  # Se define el if para que ante reiteradas ejecuciones de la notebook no se vuelva a insertar\n",
        "  if 'clase_e2' not in atributos_df:\n",
        "    atributos_df.append('clase_e2')\n",
        "\n",
        "if len(estrategias_feature_extraction)>=1:\n",
        "  print(texto)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los dataset a utilizar son: \n",
            "\tdataset-tfidf-200-prep.csv\n",
            "\tdataset-ss3-200-prep.csv\n",
            "\tdataset-lr-200-prep.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLanwDJVnFF"
      },
      "source": [
        "## 1. Instalación y Carga de librerías y funciones útiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-dNi6mDUZnb"
      },
      "source": [
        "### 1.1 Instalación de librerías\n",
        "\n",
        "Se instalan las librerías que no están en el entorno de Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644uDER_VnXj",
        "outputId": "ee4811b2-b873-42e3-db84-ee9ff1013902"
      },
      "source": [
        "# Se instala gensim que es el que tiene el modelo Word2Vec\n",
        "!pip install requests\n",
        "!pip install wget"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.7/dist-packages (3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fDuhK2V1kx"
      },
      "source": [
        "### 1.2 Funciones útiles\n",
        "\n",
        "Se cargan funciones útiles desde el repo https://github.com/jumafernandez/clasificacion_correos para la carga y balanceo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_dataset.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_dataset.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_dataset import get_clases, cargar_dataset, consolidar_df, generar_train_test_set"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxjaGIfV-rT"
      },
      "source": [
        "También se carga la función para preprocesar el texto que se usó en los otros modelos desde el repo: https://github.com/jumafernandez/clasificacion_correos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0o2NndLWDVC"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_preprocesamiento.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_preprocesamiento.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_preprocesamiento import preprocesar_correos"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOOwBxoYUoWC"
      },
      "source": [
        "### 1.2.1. Carga de librerías de procesamiento de texto\n",
        "\n",
        "Se cargan en memoria dos funciones: _grid_search_por_estrategia_representacion_ que va a iterar ajustando los hiperparámetros para las técnica de __SVM__ y _representacion_documentos_ que genera representaciones para las _features textuales_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XF6H0BGX9F9"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_clasificacion_texto.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_clasificacion_texto.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_clasificacion_texto import gridsearch_por_estrategia_representacion, representacion_documentos, gridsearch_por_tecnica"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv6R5UQWWmE"
      },
      "source": [
        "### 1.3. Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdGnbPiUk-mS"
      },
      "source": [
        "Cargo la librería warnings para no mostrar las advertencias, pandas para el manejo de df y os para verificar la existencia de los archivos en la carga de datos. Además, cargo en memoria la URL de base de los datasets y una lista de las etiquetas de las distintas clases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TsEFWTAk_qc"
      },
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Constantes con los datos\n",
        "DS_DIR = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/50jaiio/consolidados/'\n",
        "\n",
        "# Defino las clases y la cantidad a utilizar\n",
        "etiquetas = get_clases()\n",
        "CANTIDAD_CLASES = len(etiquetas)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuWVxIdck-v5"
      },
      "source": [
        "Se cargan los dataframe en memoria con el preprocesamiento de los datos:\n",
        "- Instancias LR,\n",
        "- Instancias SS3,\n",
        "- Instancias TFIDF.\n",
        "- Instancias etiquetadas manualmente.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "b9a21e41-6e5a-4115-d264-e3622a0f9805"
      },
      "source": [
        "if len(estrategias_feature_extraction)>=1:\n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_E0))\n",
        "\n",
        "  df_e0, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E0, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "  df_e0['consulta'] = pd.Series(preprocesar_correos(df_e0['consulta']))\n",
        "  test_df['consulta'] = pd.Series(preprocesar_correos(test_df['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(df_e0.clase.unique()), df_e0.clase.unique()))\n",
        "\n",
        "  # Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "  if CANTIDAD_INSTANCIAS<200:\n",
        "    df_e0 = df_e0.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "    df_e0 = df_e0.sample(frac = 1)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (3200, 25)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Cambio de Carrera' 'Cambio de Comisión'\n",
            " 'Consulta por Equivalencias' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Cursadas' 'Datos Personales'\n",
            " 'Exámenes' 'Ingreso a la Universidad' 'Pedido de Certificados'\n",
            " 'Problemas con la Clave' 'Reincorporación' 'Requisitos de Ingreso'\n",
            " 'Simultaneidad de Carreras' 'Situación Académica'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5zPZWE3-sHK"
      },
      "source": [
        "Solo en el caso que decida hacer el sistema de votación entre al menos 2 estrategias inicializo la segunda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BPhRHNBSYUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba13fff2-069b-4d05-f4a7-1d459c8f1cdd"
      },
      "source": [
        "if len(estrategias_feature_extraction)>=2:\n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_E1))\n",
        "\n",
        "  df_e1, test_df_e1, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E1, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo consulta\n",
        "  df_e1['consulta'] = pd.Series(preprocesar_correos(df_e1['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(df_e1.clase.unique()), df_e1.clase.unique()))\n",
        "\n",
        "  # Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "  if CANTIDAD_INSTANCIAS<200:\n",
        "    df_e1 = df_e1.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "    df_e1 = df_e1.sample(frac = 1)\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (3200, 25)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Cambio de Carrera' 'Cambio de Comisión'\n",
            " 'Consulta por Equivalencias' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Cursadas' 'Datos Personales'\n",
            " 'Exámenes' 'Ingreso a la Universidad' 'Pedido de Certificados'\n",
            " 'Problemas con la Clave' 'Reincorporación' 'Requisitos de Ingreso'\n",
            " 'Simultaneidad de Carreras' 'Situación Académica'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYT-zoGJ-q52"
      },
      "source": [
        "Solo en el caso que decida hacer el sistema de votación entre las 3 estrategias inicializo la tercera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4OziqC3WjET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638c099e-146e-4b59-811b-31d132234e0b"
      },
      "source": [
        "if len(estrategias_feature_extraction)>=3:\n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_E2))\n",
        "\n",
        "  df_e2, test_df_e2, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_E2, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo consulta\n",
        "  df_e2['consulta'] = pd.Series(preprocesar_correos(df_e2['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(df_e2.clase.unique()), df_e2.clase.unique()))\n",
        "\n",
        "  # Me quedo con las N cantidad de instancias con mayor score por clase\n",
        "  if CANTIDAD_INSTANCIAS<200:\n",
        "    df_e2 = df_e2.sort_values(['clase','score'], ascending=False).groupby('clase').head(CANTIDAD_INSTANCIAS).reset_index(drop=True)\n",
        "    df_e2 = df_e2.sample(frac = 1)\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (3200, 25)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Cambio de Carrera' 'Cambio de Comisión'\n",
            " 'Consulta por Equivalencias' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Cursadas' 'Datos Personales'\n",
            " 'Exámenes' 'Ingreso a la Universidad' 'Pedido de Certificados'\n",
            " 'Problemas con la Clave' 'Reincorporación' 'Requisitos de Ingreso'\n",
            " 'Simultaneidad de Carreras' 'Situación Académica'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD6F7H8Co80F"
      },
      "source": [
        "Verifico si voy a acumular los datos etiquetados manualmente a los de etiquetado no supervisado y en caso afirmativo los cargo en memoria:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjGj575EAKm9"
      },
      "source": [
        "if ETIQUETADO_MANUAL:\n",
        " \n",
        "  # Chequeo sobre si los archivos están en el working directory\n",
        "  download_files = not(path.exists(TRAIN_FILE_MANUAL))\n",
        "\n",
        "  train_df_manual, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE_MANUAL, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "  # Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "  train_df_manual['consulta'] = pd.Series(preprocesar_correos(train_df_manual['consulta']))\n",
        "\n",
        "  # Muestro salida por consola\n",
        "  print('Existen {} clases: {}.'.format(len(train_df_manual.clase.unique()), train_df_manual.clase.unique()))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RXDYdtTsl31"
      },
      "source": [
        "### 1.4 Sistema de votación entre estrategias de _feature extraction_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfXzjTUVpIzM"
      },
      "source": [
        "En primer lugar, se joinea mediante el texto de la consulta las estrategias encaradas (según sean dos o tres):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtsZgzmTZPyG"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Si se utiliza sólo 1 estrategia, se inicializa el df_join con solo esa\n",
        "if len(estrategias_feature_extraction)==1:\n",
        "  df_join = df_e0\n",
        "\n",
        "# Si se utilizan al menos 2 estrategias, se incorpora también la 2da\n",
        "if len(estrategias_feature_extraction)>=2:\n",
        "  df_join = pd.merge(df_e0, df_e1, on='consulta', how='left', suffixes=(None, \"_x\"))\n",
        "\n",
        "# Si están las 3 estrategias, se incorpora también la 3era\n",
        "if len(estrategias_feature_extraction)==3:\n",
        "  df_join = pd.merge(df_join, df_e2, on='consulta', how='left', suffixes=(None, \"_y\"))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMv6W-y4MbJ"
      },
      "source": [
        "Borro las instancias con faltantes y verifico el resultado la dimensionalidad del df:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA6GiR72ZaGi",
        "outputId": "c9acc80f-d1a8-4db2-c119-41637e742730"
      },
      "source": [
        "if 'df_join' in globals():\n",
        "  df_join = df_join.dropna()\n",
        "  \n",
        "  print(df_join.shape)\n",
        "\n",
        "  print(df_join.head())"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2357, 73)\n",
            "                                            consulta  ...               clase_y\n",
            "0  hola hice hace mes tramite online boleto estud...  ...  Boleto Universitario\n",
            "1  hola pagina dice asignado boleto estudiantil p...  ...  Boleto Universitario\n",
            "2  hace casi mes hice tramite sube cargan meses c...  ...  Boleto Universitario\n",
            "3  hola tal buenos dias queria consultar benefici...  ...  Boleto Universitario\n",
            "6  hola buenos dias comunicaba tema boleto estudi...  ...  Boleto Universitario\n",
            "\n",
            "[5 rows x 73 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKK_XeCr4m59"
      },
      "source": [
        "Renombro las clases en función de las estrategias y me quedo sólo con las instancias en que la clase coincide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfUF6_C4i2E"
      },
      "source": [
        "if len(estrategias_feature_extraction)==3:\n",
        "  df_join.rename(columns={'clase_x': 'clase_e0', 'clase_y': 'clase_e1', 'clase': 'clase_e2'}, inplace=True)\n",
        "  df_join['match_clase'] = ((df_join['clase_e0'] == df_join['clase_e1']) & (df_join['clase_e1'] == df_join['clase_e2']))\n",
        "elif len(estrategias_feature_extraction)==2:\n",
        "  df_join.rename(columns={'clase': 'clase_e0', 'clase_x': 'clase_e1'}, inplace=True)\n",
        "  df_join['match_clase'] = df_join['clase_e0'] == df_join['clase_e1']\n",
        "elif len(estrategias_feature_extraction)==1:\n",
        "  df_join.rename(columns={'clase': 'clase_e0'}, inplace=True)\n",
        "  # Esto se hace por compatibilidad con las otras alternativas (2 y 3 estrategias)\n",
        "  df_join['match_clase'] = df_join['clase_e0'] == df_join['clase_e0']\n",
        "\n",
        "if 'df_join' in globals():\n",
        "  # Me quedo sólo con las instancias en que la clase coincide\n",
        "  train_df_join = df_join.query('match_clase == True').reset_index()\n",
        "\n",
        "  train_df_join.shape"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phy2ZVCl4KoT"
      },
      "source": [
        "Me quedo solo con los atributos que me interesan (elimino duplicados):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieGYeC6q4K0B"
      },
      "source": [
        "if 'df_join' in globals():\n",
        "  train_df_join = train_df_join[atributos_df]\n",
        "\n",
        "  train_df_join.columns"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-e0IcaYnf8f"
      },
      "source": [
        "Me quedo sólo con una columna de clase dado que son las 3 iguales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oezp0Fvk7QT"
      },
      "source": [
        "if 'df_join' in globals():\n",
        "  # Tomo una clase al azar, dado que coinciden las 3\n",
        "  train_df_join.rename(columns={'clase_e0': 'clase'}, inplace=True)\n",
        "\n",
        "  # Elimino las columnas que no necesito\n",
        "  if len(estrategias_feature_extraction)>=2:\n",
        "    train_df_join.drop(['clase_e1'], inplace=True, axis=1)\n",
        "\n",
        "  if len(estrategias_feature_extraction)==3:\n",
        "    train_df_join.drop(['clase_e2'], inplace=True, axis=1)\n",
        "\n",
        "  train_df_join.shape"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IKK2WwlVLye"
      },
      "source": [
        "Me guardo la columna del score de Elasticsearch para no generar incompatibilidades:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daumQbloVLNa"
      },
      "source": [
        "if 'df_join' in globals():\n",
        "  score = train_df_join['score']\n",
        "  train_df_join.drop('score', inplace=True, axis=1)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_WMVnGCAt66"
      },
      "source": [
        "if len(estrategias_feature_extraction)>=1:\n",
        "  if ETIQUETADO_MANUAL:\n",
        "    train_df = pd.concat([train_df_manual, train_df_join], axis=0).reset_index(drop=True)\n",
        "  else:\n",
        "    train_df = train_df_join\n",
        "else:\n",
        "  train_df = train_df_manual"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qdJuRmxoaXV"
      },
      "source": [
        "Muestro el dataframe resultante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "-z_-PYK9nU_7",
        "outputId": "c0a3547b-4d75-4226-899f-aa11b4d314db"
      },
      "source": [
        "# pd.set_option('display.max_colwidth', None)\n",
        "# pd.set_option('display.max_rows', None)\n",
        "train_df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consulta</th>\n",
              "      <th>dia_semana</th>\n",
              "      <th>semana_del_mes</th>\n",
              "      <th>mes</th>\n",
              "      <th>cuatrimestre</th>\n",
              "      <th>anio</th>\n",
              "      <th>hora_discretizada</th>\n",
              "      <th>dni_discretizado</th>\n",
              "      <th>legajo_discretizado</th>\n",
              "      <th>posee_legajo</th>\n",
              "      <th>posee_telefono</th>\n",
              "      <th>carrera_valor</th>\n",
              "      <th>proveedor_correo</th>\n",
              "      <th>cantidad_caracteres</th>\n",
              "      <th>proporcion_mayusculas</th>\n",
              "      <th>proporcion_letras</th>\n",
              "      <th>cantidad_tildes</th>\n",
              "      <th>cantidad_palabras</th>\n",
              "      <th>cantidad_palabras_cortas</th>\n",
              "      <th>proporcion_palabras_distintas</th>\n",
              "      <th>frecuencia_signos_puntuacion</th>\n",
              "      <th>cantidad_oraciones</th>\n",
              "      <th>utiliza_codigo_asignatura</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hola hice hace mes tramite online boleto estud...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.797468</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>25</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.021097</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hola pagina dice asignado boleto estudiantil p...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>207</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.816425</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>17</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.019324</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hace casi mes hice tramite sube cargan meses c...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>299</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.799331</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>33</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.016722</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hola tal buenos dias queria consultar benefici...</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2018</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>13</td>\n",
              "      <td>425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>3</td>\n",
              "      <td>75</td>\n",
              "      <td>38</td>\n",
              "      <td>0.773333</td>\n",
              "      <td>0.025882</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hola buenos dias comunicaba tema boleto estudi...</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.803774</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td>30</td>\n",
              "      <td>0.897959</td>\n",
              "      <td>0.015094</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Boleto Universitario</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            consulta  ...                 clase\n",
              "0  hola hice hace mes tramite online boleto estud...  ...  Boleto Universitario\n",
              "1  hola pagina dice asignado boleto estudiantil p...  ...  Boleto Universitario\n",
              "2  hace casi mes hice tramite sube cargan meses c...  ...  Boleto Universitario\n",
              "3  hola tal buenos dias queria consultar benefici...  ...  Boleto Universitario\n",
              "4  hola buenos dias comunicaba tema boleto estudi...  ...  Boleto Universitario\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJHaVhO8ZpRx",
        "outputId": "31c909df-55eb-43b0-9abb-986251dcefb5"
      },
      "source": [
        "X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, '3-4-NGRAM-CHARS', MAX_TKS=ATRIBUTOS_DINAMICOS)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrategia de representación: 3-4-NGRAM-CHARS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndyqr3kmakbB",
        "outputId": "7ec349f2-4751-443b-9d6d-b0e36f69d2db"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(993, 3022)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## 2. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6VPw5NNYje"
      },
      "source": [
        "### 2.1 Modelo general (clasificación en las 16 clases)\n",
        "\n",
        "En primer lugar se trabaja con un único clasificador que clasifica y testea las instancias en las 16 clases posibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgPWXtpU_7v"
      },
      "source": [
        "#### 2.1.1 Definición del espacio de búsqueda\n",
        "\n",
        "Se define el espacio de búsqueda para el ajuste de hiperparámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TOc1GcX-rg"
      },
      "source": [
        "# Defino los parámetros para GridSearchCV\n",
        "params_svm = {'SVM__C': [0.1, 1, 10], \n",
        "              'SVM__gamma': [0.01, 0.1, 1],\n",
        "              'SVM__class_weight': [None, 'balanced'],\n",
        "              'SVM__kernel': ['rbf', 'linear', 'sigmoid'],\n",
        "              'SVM__probability': [False]\n",
        "              }"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnm8yPmYGAR"
      },
      "source": [
        "Se ejecuta el ajuste de hiperparámetros para cada estrategia de representación en función del espacio de búsqueda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSOquuAYGPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ddfa33a0-c8e4-4d8f-8f6a-ee08d4e9bc1b"
      },
      "source": [
        "modelos_grid = []\n",
        "representacion_grid = []\n",
        "metricas_grid = []\n",
        "NO_CORRIDA = True\n",
        "\n",
        "# Modulo para la hora (a efectos de calcular los tiempos de ejecución)\n",
        "import time\n",
        "\n",
        "if NO_CORRIDA:\n",
        "  # Se hace una búsqueda grid por estrategia de representación\n",
        "  for estrategia in estrategias_representacion:\n",
        "    \n",
        "    # Generamos los datos de train y test por estrategia\n",
        "    X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, estrategia, MAX_TKS=ATRIBUTOS_DINAMICOS)\n",
        "\n",
        "    # Se imprime la hora del servidor\n",
        "    hora_servidor = time.strftime('%H:%M:%S', time.localtime())\n",
        "    print(f'Hora de inicio de la búsqueda grid: {hora_servidor}.')\n",
        "\n",
        "    # Llamo a la función que realiza el gridsearch por estrategia  \n",
        "    clf_grid, metrics_grid = gridsearch_por_tecnica(X_train, y_train, X_test, y_test, tecnica, params_svm)\n",
        "\n",
        "    # Guardamos el mejor modelo para cada estrategia de representación\n",
        "    modelos_grid.append(clf_grid)\n",
        "    representacion_grid.append(estrategia)\n",
        "    metricas_grid.append(metrics_grid)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrategia de representación: BINARIO\n",
            "Hora de inicio de la búsqueda grid: 15:24:13.\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   38.5s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-faf4e7161278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Llamo a la función que realiza el gridsearch por estrategia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclf_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsearch_por_tecnica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtecnica\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_svm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Guardamos el mejor modelo para cada estrategia de representación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/funciones_clasificacion_texto.py\u001b[0m in \u001b[0;36mgridsearch_por_tecnica\u001b[0;34m(X_train, y_train, X_test, y_test, tecnica, parameters)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;31m# Instancio y \"entreno\" el GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0mgrid_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;31m# Se realizan las predicciones sobre el conjunto de validación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BLl1MGrOdXs"
      },
      "source": [
        "A partir de los mejores hiperparámetros encontrados para cada estrategia de representación de correos, se busca cual es la estrategia que generó el mayor _accuracy_ (medida totalmente arbitraria):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZPszyNuh1d"
      },
      "source": [
        "max_accuracy = 0\n",
        "for i in range(1, len(metricas_grid)):\n",
        "  if metricas_grid[i]['accuracy'] > metricas_grid[max_accuracy]['accuracy']:\n",
        "    max_accuracy = i\n",
        "\n",
        "representacion_max = representacion_grid[max_accuracy]\n",
        "\n",
        "# Se le quita el prefijo asignado a los parametricos para la búsqueda grid\n",
        "params_max = params = {x.replace(\"SVM__\", \"\"): v for x, v in modelos_grid[max_accuracy].best_params_.items()}\n",
        "\n",
        "# Se guardan las métricas y el modelo \"ganador\"\n",
        "metricas_max = metricas_grid[max_accuracy]\n",
        "clf_max = modelos_grid[max_accuracy]\n",
        "\n",
        "print(f'Sistema de generación de instancias: {estrategias_feature_extraction}', sep=\"\")\n",
        "if ACUMULATIVO:\n",
        "  print(f'Las instancias se ACUMULAN a las etiquetadas manualmente')\n",
        "else:\n",
        "  print(f'Las instancias NO SE ACUMULAN a las etiquetadas manualmente')\n",
        "\n",
        "print(f'El modelo más eficaz es {tecnica} con la estrategia de representación {representacion_max} y los parámetros:\\n {params_max}')\n",
        "print(f'El modelo brinda las siguientes métricas de selección:\\n {metricas_max}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjoUvaOgh00W"
      },
      "source": [
        "#### 2.1.2 Modelo generado\n",
        "\n",
        "En función de los mejores hiperparámetros y estrategia de representación encontrados con la búsqueda Grid, ajusto el modelo para obtener las métricas.\n",
        "\n",
        "En primer lugar genero los datos de train y test con la estrategia de representación ganadora:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfU5JT1vh0J3"
      },
      "source": [
        "X_train, y_train, X_test, y_test = generar_train_test_set(train_df, test_df, representacion_max, MAX_TKS=ATRIBUTOS_DINAMICOS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBgo7dzPLkv5"
      },
      "source": [
        "__[VARIANTE]__ Se entrena el modelo con los mejores hiperparámetros encontrados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXrnHa4qH8in"
      },
      "source": [
        "# from sklearn.svm import SVC\n",
        "# clf = SVC(**params_max)\n",
        "\n",
        "# Entreno el modelo con los parámetros\n",
        "# clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzVZFzCTVTSZ"
      },
      "source": [
        "Se predicen las instancias de testeo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNoj8Gshc09R"
      },
      "source": [
        "y_pred = clf_max.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIpzEIaOWKNa"
      },
      "source": [
        "#### 2.1.3 Métricas de selección"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-THNpdciSP"
      },
      "source": [
        "from sklearn import metrics #Importar el módulo metrics de scikit-learn\n",
        "\n",
        "# Vamos a testear el modelo\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Vemos un reporte de clasificación de varias métricas\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQJL_Y-CWzKh"
      },
      "source": [
        "Se genera la matriz de confusión del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYUVKbHldjKq"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mat = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "\n",
        "plt.xlabel('Observada')\n",
        "plt.ylabel('Predicha');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P14cduVB6pZk"
      },
      "source": [
        "### 3. Análisis del error\n",
        "\n",
        "A continuación se intenta entender la baja de _accuracy_ para el etiquetado a partir de TF-IDF.\n",
        "\n",
        "Para ello, se genera el dataset de train con: <br/>\n",
        "| consulta | clase | score |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Yzf0qf36oL2"
      },
      "source": [
        "df_train_e = train_df[['consulta', 'clase']]\n",
        "df_train_e['score'] = score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJVVj9Kk6uhd"
      },
      "source": [
        "Genero un dataframe con los scores promedios por clase, el accuracy por clase y el _count_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRdVnXSN6wkJ"
      },
      "source": [
        "df_error = df_train_e.groupby(['clase']).mean().reset_index()\n",
        "# Accuracy por clase\n",
        "avg_class = mat.diagonal()/mat.sum(axis=1)\n",
        "df_error['accuracy'] = pd.Series(avg_class)\n",
        "\n",
        "df_error['count'] = mat.sum(axis=1)\n",
        "\n",
        "df_error\n",
        "df_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRKtSNPr63Oo"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "sns.scatterplot(data=df_error, x=\"score\", y=\"accuracy\", hue=\"count\", size=\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "## Referencias\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}