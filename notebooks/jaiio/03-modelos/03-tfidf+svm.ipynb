{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-tfidf+svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jaiio/03-modelos/03-tfidf%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# TF-IDF+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos a partir de los datos etiquetados automáticamente a partir de las _features_ extraidas del train dataset con la estrategia de TF-IDF y SVM.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLanwDJVnFF"
      },
      "source": [
        "## 1. Instalación y Carga de librerías y funciones útiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-dNi6mDUZnb"
      },
      "source": [
        "### 1.1 Instalación de librerías\n",
        "\n",
        "Se instalan las librerías que no están en el entorno de Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644uDER_VnXj",
        "outputId": "231d19a6-d89d-4225-9c36-99710c8aa5db"
      },
      "source": [
        "# Se instala gensim que es el que tiene el modelo Word2Vec\n",
        "!pip install requests\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=378424de7052d845c803470762d56129bc1f1daa744799e25f5b88955332f65c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fDuhK2V1kx"
      },
      "source": [
        "### 1.2 Funciones útiles\n",
        "\n",
        "Se cargan funciones útiles desde el repo https://github.com/jumafernandez/clasificacion_correos para la carga y balanceo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_dataset.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_dataset.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_dataset import get_clases, cargar_dataset, consolidar_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxjaGIfV-rT"
      },
      "source": [
        "También se carga la función para preprocesar el texto que se usó en los otros modelos desde el repo: https://github.com/jumafernandez/clasificacion_correos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0o2NndLWDVC"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_preprocesamiento.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_preprocesamiento.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_preprocesamiento import preprocesar_correos"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv6R5UQWWmE"
      },
      "source": [
        "### 1.3. Carga de datos\n",
        "\n",
        "Se carga el dataframe en memoria con el preprocesamiento de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "23183f55-3d2e-4691-9789-478e9853bb3a"
      },
      "source": [
        "import warnings\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Constantes con los datos\n",
        "DS_DIR = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/50jaiio/consolidados/'\n",
        "TRAIN_FILE = 'dataset-tfidf-200-boosting-prep.csv'\n",
        "TEST_FILE = 'correos-test-jaiio-20.csv'\n",
        "\n",
        "# Chequeo sobre si los archivos están en el working directory\n",
        "download_files = not(path.exists(TRAIN_FILE))\n",
        "\n",
        "etiquetas = get_clases()\n",
        "\n",
        "# Defino la cantidad de clases a utilizar\n",
        "CANTIDAD_CLASES = len(etiquetas)\n",
        "\n",
        "train_df, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "# Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "import pandas as pd\n",
        "train_df['consulta'] = pd.Series(preprocesar_correos(train_df['consulta']))\n",
        "test_df['consulta'] = pd.Series(preprocesar_correos(test_df['consulta']))\n",
        "\n",
        "# Muestro salida por consola\n",
        "print('Existen {} clases: {}.'.format(len(train_df.clase.unique()), train_df.clase.unique()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se inicia descarga de los datasets.\n",
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (1600, 25)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 16 clases: ['Boleto Universitario' 'Cambio de Carrera' 'Cambio de Comisión'\n",
            " 'Consulta por Equivalencias' 'Consulta por Legajo'\n",
            " 'Consulta sobre Título Universitario' 'Cursadas' 'Datos Personales'\n",
            " 'Exámenes' 'Ingreso a la Universidad' 'Pedido de Certificados'\n",
            " 'Problemas con la Clave' 'Reincorporación' 'Requisitos de Ingreso'\n",
            " 'Simultaneidad de Carreras' 'Situación Académica'].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbkuvaa21DU"
      },
      "source": [
        "### 1.4 Selección de Instancias\n",
        "\n",
        "Se seleccionan las instancias en función del _score_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA5l-m6p20Vv"
      },
      "source": [
        "#train_df = train_df.query('score>20').reset_index()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD-htjM5bXSI"
      },
      "source": [
        "Y también pueden seleccionarse en función de la cantidad por clase:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YinCBlAKbWLg"
      },
      "source": [
        "N = 100\n",
        "\n",
        "if N<200:\n",
        "  train_df = train_df.groupby('clase').head(N).reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A06GLkzJ3Rmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a6a28d-21c3-4904-be22-b91158f0afd5"
      },
      "source": [
        "count_train = train_df.clase.value_counts().sort_index()\n",
        "\n",
        "count_train.index"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Boleto Universitario', 'Cambio de Carrera', 'Cambio de Comisión',\n",
              "       'Consulta por Equivalencias', 'Consulta por Legajo',\n",
              "       'Consulta sobre Título Universitario', 'Cursadas', 'Datos Personales',\n",
              "       'Exámenes', 'Ingreso a la Universidad', 'Pedido de Certificados',\n",
              "       'Problemas con la Clave', 'Reincorporación', 'Requisitos de Ingreso',\n",
              "       'Simultaneidad de Carreras', 'Situación Académica'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IKK2WwlVLye"
      },
      "source": [
        "Me guardo la columna del score de Elasticsearch para no generar incompatibilidades:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daumQbloVLNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70d5be3-15d4-4681-fa23-abe9ee5b8782"
      },
      "source": [
        "score = train_df['score']\n",
        "train_df.drop(['score'], inplace=True, axis=1)\n",
        "\n",
        "train_df.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## 2. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOOwBxoYUoWC"
      },
      "source": [
        "### 2.1. Carga de librerías de procesamiento de texto\n",
        "\n",
        "Se cargan en memoria dos funciones: _grid_search_por_estrategia_representacion_ que va a iterar ajustando los hiperparámetros para las técnica de __SVM__ y _representacion_documentos_ que genera representaciones para las _features textuales_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XF6H0BGX9F9"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/funciones_clasificacion_texto.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_clasificacion_texto.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_clasificacion_texto import gridsearch_por_estrategia_representacion, representacion_documentos"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6VPw5NNYje"
      },
      "source": [
        "### 2.2 Modelo general (clasificación en las 16 clases)\n",
        "\n",
        "En primer lugar se trabaja con un único clasificador que clasifica y testea las instancias en las 16 clases posibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgPWXtpU_7v"
      },
      "source": [
        "#### 2.2.1 Definición del espacio de búsqueda\n",
        "\n",
        "Se define el espacio de búsqueda para el ajuste de hiperparámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TOc1GcX-rg"
      },
      "source": [
        "# Defino una lista con los esquemas de representación\n",
        "estrategias_representacion = ['3-4-NGRAM-CHARS', '1-2-NGRAM-WORDS']\n",
        "modelo = 'SVM'\n",
        "\n",
        "# Defino los parámetros para GridSearchCV\n",
        "params_svm = {'SVM__C': [0.1, 1, 10, 100], \n",
        "              'SVM__gamma': [0.01, 0.1, 1],\n",
        "              'SVM__class_weight': [None, 'balanced'],\n",
        "              'SVM__kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "              }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnm8yPmYGAR"
      },
      "source": [
        "Se ejecuta el ajuste de hiperparámetros para cada estrategia de representación en función del espacio de búsqueda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSOquuAYGPK"
      },
      "source": [
        "NO_CORRIDA = False\n",
        "\n",
        "if NO_CORRIDA:\n",
        "  for estrategia in estrategias_representacion:\n",
        "    # Llamo a la función que realiza el gridsearch por estrategia  \n",
        "    gridsearch_por_estrategia_representacion(train_df, test_df, estrategia, modelo, params_svm, None, atr_consulta='consulta')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjoUvaOgh00W"
      },
      "source": [
        "#### 2.2.2 Modelo generado\n",
        "\n",
        "En función de los mejores hiperparámetros encontrados con la búsqueda Grid, ajusto el modelo para obtener las métricas (por un bug en la función ya solucionado):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfU5JT1vh0J3",
        "outputId": "27ab4634-ca30-467d-fa0e-d1b7fa88e9f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mejores Parámetros según GridSearchCV:\n",
        "# DOCS = 200, boosting\n",
        "# Parámetros: Parámetros: {'SVM__C': 1, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', \n",
        "# 'SVM__probability': True, 'clasificador': 'SVM', 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.74, 'precision': 0.6004699248120301,\n",
        "# 'recall': 0.6847894888530615, 'f1_score': 0.598663821952355}\n",
        "# DOCS = 100, boosting, accuracy: 0.69\n",
        "# Parámetros: {'SVM__C': 1, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'sigmoid', 'clasificador': 'SVM', 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.69, 'precision': 0.6011043643856144, 'recall': 0.6518977316066847, 'f1_score': 0.566446113504937}\n",
        "# DOCS = 50, boosting, accuracy: 0.64\n",
        "# DOCS = 20, boosting, accuracy: 0.55\n",
        "# DOCS = 100, accuracy: 0.67\n",
        "# DOCS = 50, accuracy: 0.63\n",
        "# DOCS = 20, accuracy: 0.56\n",
        "# DOCS = 100, NOT boosting Parámetros: {'SVM__C': 1, 'SVM__class_weight': None, 'SVM__gamma': 0.1, 'SVM__kernel': 'sigmoid', 'clasificador': 'SVM', 'estrategia': 'TFIDF', 'accuracy': 0.68, 'precision': 0.5236766751158198, 'recall': 0.5970173705013522, 'f1_score': 0.5222067737005347}\n",
        "\n",
        "params_svm = {'SVM__C': [1], \n",
        "              'SVM__gamma': [0.01],\n",
        "              'SVM__class_weight': [None],\n",
        "              'SVM__kernel': ['sigmoid'],\n",
        "              'SVM__probability': [True]\n",
        "              }\n",
        "\n",
        "clf, X_test, y_test = gridsearch_por_estrategia_representacion(train_df, test_df, '3-4-NGRAM-CHARS', 'SVM', params_svm, None, atr_consulta='consulta')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzVZFzCTVTSZ"
      },
      "source": [
        "Se predicen las instancias de testeo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNoj8Gshc09R"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgqhtxfYxB0c"
      },
      "source": [
        "Además, se utiliza el método _predict\\_proba_ para calcular la probabilidad asociada a la clasificación de cada instancia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhOC_7_zxB8a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_pred_proba = np.around(clf.predict_proba(X_test), 2)\n",
        "\n",
        "y_max_proba = np.amax(y_pred_proba, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZG-04FYxCXh"
      },
      "source": [
        "y_max_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU3VO818xCEQ"
      },
      "source": [
        "Se genera un dataframe con las clases observadas para test, las predicciones y las probabilidades asociadas para verificar si hay relación entre las proba y los errores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcObOGvExCKr"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "resultados = pd.concat([pd.Series(y_test), pd.Series(y_pred), pd.Series(y_max_proba)], axis=1)\n",
        "resultados.columns = ['clase', 'prediccion', 'max_proba']\n",
        "resultados['correcto'] = resultados['clase'] == resultados['prediccion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLfOub5zxS5A"
      },
      "source": [
        "Se calcula el _accuracy_ para las predicciones con una proba>0.5 y se obtiene una mejora sustancial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ8JgFRDxVMx"
      },
      "source": [
        "sum(resultados[resultados.max_proba>0.5]['correcto'])/resultados[resultados.max_proba>0.5]['correcto'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIpzEIaOWKNa"
      },
      "source": [
        "#### 2.2.3 Métricas de selección"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cied9MM_WNvG"
      },
      "source": [
        "##### 2.2.3.1. Matriz de confusión\n",
        "\n",
        "A continuación, se calcula la matriz de confusión para cada clase para el recorte con proba>0.5 y para el modelo con la totalidad de instancias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeK6rWwqZInr"
      },
      "source": [
        "from sklearn import metrics #Importar el módulo metrics de scikit-learn\n",
        "\n",
        "# Vamos a testear el modelo\n",
        "print(\"Accuracy:\", metrics.accuracy_score(resultados[resultados.max_proba>0.5]['clase'], resultados[resultados.max_proba>0.5]['prediccion']))\n",
        "\n",
        "# Vemos un reporte de clasificación de varias métricas\n",
        "print(metrics.classification_report(resultados[resultados.max_proba>0.5]['clase'], resultados[resultados.max_proba>0.5]['prediccion']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-THNpdciSP"
      },
      "source": [
        "from sklearn import metrics #Importar el módulo metrics de scikit-learn\n",
        "\n",
        "# Vamos a testear el modelo\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Vemos un reporte de clasificación de varias métricas\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8dTwLl5dYu-"
      },
      "source": [
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYUVKbHldjKq"
      },
      "source": [
        "import numpy as np\n",
        "import seaborn as sns; sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mat = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=etiquetas, yticklabels=etiquetas)\n",
        "\n",
        "plt.xlabel('Observada')\n",
        "plt.ylabel('Predicha');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAUagcD3dVc9"
      },
      "source": [
        "### 3. Análisis del error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaLRiFGFdaOk"
      },
      "source": [
        "A continuación se intenta entender la baja de _accuracy_ para el etiquetado a partir de TF-IDF.\n",
        "\n",
        "Para ello, se genera el dataset de train con: <br/>\n",
        "| consulta | clase | score |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifFxF-nJeAcg"
      },
      "source": [
        "df_train_e = train_df[['consulta', 'clase']]\n",
        "df_train_e['score'] = score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv_Bmj3-gvAx"
      },
      "source": [
        "Genero un dataframe con los scores promedios por clase, el accuracy por clase y el _count_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcPl1MtlesUO"
      },
      "source": [
        "df_error = df_train_e.groupby(['clase']).mean().reset_index()\n",
        "\n",
        "# Accuracy por clase\n",
        "avg_class = mat.diagonal()/mat.sum(axis=1)\n",
        "df_error['accuracy'] = pd.Series(avg_class)\n",
        "\n",
        "df_error['count_test'] = mat.sum(axis=1)\n",
        "\n",
        "df_error['count_train'] = count_train.values\n",
        "\n",
        "df_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYqP5oylx95w"
      },
      "source": [
        "df_error[['accuracy', 'score']].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pu4dIekyD23"
      },
      "source": [
        "GUARDA_ACC = True\n",
        "\n",
        "if GUARDA_ACC:\n",
        "  from google.colab import drive\n",
        "  drive.mount('drive')\n",
        "\n",
        "  df_error.to_csv('accuracy_by_class-tfidf.csv', index=False)\n",
        "  !cp accuracy_by_class-tfidf.csv \"drive/My Drive/jaiio-prep/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNEWhC5jf5Pc"
      },
      "source": [
        "# Cargo las librerías y defino el paño blanco\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Ploteo el gráfico general\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(data=df_error, x=\"score\", y=\"accuracy\", hue=\"count_train\", size=\"count_train\")\n",
        "\n",
        "# Pongo los nombres de las clases\n",
        "for i in range(df_error.shape[0]):\n",
        "\n",
        "  # Filtro solo los puntos con más de N_ap apariciones\n",
        "  N_ap = 30\n",
        "  if df_error.count_train[i]>=N_ap:\n",
        "    plt.text(x=df_error.score[i]+0.01,\n",
        "             y=df_error.accuracy[i]+0.01,\n",
        "             s=df_error.clase[i])\n",
        "\n",
        "plt.title(\"Análisis gráfico del error por clase\")           #title\n",
        "# plt.xlim(df_error.score.min()-1,df_error.score.max()+1)   #set x limit\n",
        "plt.ylim(0, df_error.accuracy.max()+0.15)                   #set y limit\n",
        "plt.xlabel(\"Elasticsearch score avg para la clase\")         #y label\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "## Referencias\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}