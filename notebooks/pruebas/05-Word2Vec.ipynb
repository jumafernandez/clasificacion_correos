{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-Word2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7mBRIKgfEqT0SyACuWW7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/05-Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTD65pStwWuO"
      },
      "source": [
        "# Probando Word2Vec con embeddings pre-entrenados\r\n",
        "\r\n",
        "1. Instalo gensim:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY1vTrwvtynw",
        "outputId": "2c4a6122-21de-431c-f334-fab99af5789f"
      },
      "source": [
        "!pip install gensim\r\n",
        "import gensim"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAkTZSEqwlMv"
      },
      "source": [
        "2. Descargo los embeddings pre-entrenados en español:\r\n",
        "\r\n",
        "    __Source:__ https://github.com/dccuchile/spanish-word-embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEa8IbABwU9R"
      },
      "source": [
        "import os.path\r\n",
        "from os import path\r\n",
        "\r\n",
        "if not(path.exists(\"SBW-vectors-300-min5.bin.gz\")):\r\n",
        "  !wget http://cs.famaf.unc.edu.ar/~ccardellino/SBWCE/SBW-vectors-300-min5.bin.gz\r\n",
        "\r\n",
        "# Source: https://github.com/dccuchile/spanish-word-embeddings"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_xyelTHxEFE"
      },
      "source": [
        "3. Cargo el modelo pre-entrenado en el módulo Word2Vec:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDThn-Wtt9dL"
      },
      "source": [
        "from gensim.models import Word2Vec\r\n",
        "\r\n",
        "filename=\"SBW-vectors-300-min5.bin.gz\"\r\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=True)\r\n",
        "embeddings.init_sims(replace=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kry-jnToxZg0"
      },
      "source": [
        "4. Exploro los términos 1000 a 1050 del vocabulario, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3lJcr4xCnu",
        "outputId": "83434f4d-9b2a-478d-b083-7d17c0bcacfc"
      },
      "source": [
        "from itertools import islice\r\n",
        "list(islice(embeddings.vocab, 1000, 1050))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['refiere',\n",
              " 'hayan',\n",
              " 'gt',\n",
              " 'ciudades',\n",
              " 'Asuntos',\n",
              " 'estilo',\n",
              " 'lleva',\n",
              " 'dispuesto',\n",
              " 'curso',\n",
              " 'bienes',\n",
              " 'imagen',\n",
              " 'Costa',\n",
              " 'gubernamentales',\n",
              " 'distintos',\n",
              " 'sectores',\n",
              " 'realizado',\n",
              " 'continuación',\n",
              " 'pruebas',\n",
              " 'terreno',\n",
              " 'especies',\n",
              " 'propiedad',\n",
              " 'Sus',\n",
              " 'indicó',\n",
              " 'ocasiones',\n",
              " 'presenta',\n",
              " 'instalaciones',\n",
              " 'presentar',\n",
              " 'regiones',\n",
              " 'haciendo',\n",
              " 'prueba',\n",
              " 'Federación',\n",
              " 'III',\n",
              " 'allí',\n",
              " 'escuela',\n",
              " 'diálogo',\n",
              " 'aplicar',\n",
              " 'Más',\n",
              " 'hotel',\n",
              " 'quiere',\n",
              " 'responsable',\n",
              " 'edificio',\n",
              " 'obligaciones',\n",
              " 'entidad',\n",
              " 'cuarto',\n",
              " 'declaraciones',\n",
              " 'señor',\n",
              " 'delito',\n",
              " 'intereses',\n",
              " 'inversión',\n",
              " 'Banco']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kkx9XdI3nsO"
      },
      "source": [
        "5. Hacemos una prueba semántica, buscando el termino mas similar a mujer y rey que no sea hombre:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ft72hZ0TLQ",
        "outputId": "378cdf47-e5fd-43fd-c305-eef4e5d5710a"
      },
      "source": [
        "result = embeddings.most_similar(positive=['mujer', 'rey'], negative=['hombre'], topn=1)\r\n",
        "print(result)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('reina', 0.7493031024932861)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKwV3G8e7W0O"
      },
      "source": [
        "6. Levanto mis datos con las etiquetas y trato desbalanceo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "gPtVO6ZM7YyN",
        "outputId": "d1390e4b-9eca-4fd4-d6c5-6927ef603ea9"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Descargo el archivo con las consultas que está en Github\r\n",
        "if not(path.exists(\"Correos_Seleccionados_y_Etiquetados.csv\")):\r\n",
        "  !wget https://raw.githubusercontent.com/jumafernandez/UNLP/master/TFI/data/Correos_Seleccionados_y_Etiquetados.csv\r\n",
        "\r\n",
        "df = pd.read_csv('Correos_Seleccionados_y_Etiquetados.csv', delimiter=\"|\")\r\n",
        "\r\n",
        "# Paso a otras consultas las clases minoritatias (trato desbalanceo)\r\n",
        "cantidad_clases=3\r\n",
        "clases = df.Clase.value_counts()\r\n",
        "clases_minoritarias = clases.iloc[cantidad_clases:].keys().to_list()\r\n",
        "df.Clase[df['Clase'].isin(clases_minoritarias)] = \"Otras Consultas\"\r\n",
        "\r\n",
        "df.head()\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fecha</th>\n",
              "      <th>Hora</th>\n",
              "      <th>Apellido y Nombre</th>\n",
              "      <th>Legajo</th>\n",
              "      <th>Documento</th>\n",
              "      <th>Carrera</th>\n",
              "      <th>Teléfono</th>\n",
              "      <th>E-mail</th>\n",
              "      <th>Consulta</th>\n",
              "      <th>Respuesta</th>\n",
              "      <th>Clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>08-05-2019</td>\n",
              "      <td>10:49:26</td>\n",
              "      <td>florencia  roland</td>\n",
              "      <td>169336</td>\n",
              "      <td>33829069</td>\n",
              "      <td>licenciatura en enfermeria(52)</td>\n",
              "      <td>1121550750</td>\n",
              "      <td>rolandflorencia@gmail.com</td>\n",
              "      <td>hola quiero anotarme a las materias ,para el s...</td>\n",
              "      <td>te falta presentar alguna de las vacunas   sal...</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>08-08-2017</td>\n",
              "      <td>12:29:59</td>\n",
              "      <td>lourdes vanesa gómez</td>\n",
              "      <td>150786</td>\n",
              "      <td>33220121</td>\n",
              "      <td>licenciatura en enfermeria(52)</td>\n",
              "      <td>1131066251</td>\n",
              "      <td>vane_male@outlook.com</td>\n",
              "      <td>hola buenos días! quería saber cuando voy a po...</td>\n",
              "      <td>lo que falta es que la coordinación autorice l...</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>05-31-2017</td>\n",
              "      <td>01:30:49</td>\n",
              "      <td>karg solange</td>\n",
              "      <td>156535</td>\n",
              "      <td>43455018</td>\n",
              "      <td>contador publico(54)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>solangekarg8@gmail.com</td>\n",
              "      <td>hola quisiera saber si en la consulta de situa...</td>\n",
              "      <td>no, las notas de parciales no aparecen en tu s...</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02-05-2018</td>\n",
              "      <td>22:58:24</td>\n",
              "      <td>topa maria luz</td>\n",
              "      <td>155395</td>\n",
              "      <td>38859638</td>\n",
              "      <td>licenciatura en trabajo social(5)</td>\n",
              "      <td>1566431259</td>\n",
              "      <td>luztopa@hotmail.com</td>\n",
              "      <td>buenas noches. en mi situacion academica apare...</td>\n",
              "      <td>es que tenes que mirar por la opción finales l...</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08-06-2016</td>\n",
              "      <td>13:16:16</td>\n",
              "      <td>yanet elizabeth marquez</td>\n",
              "      <td>115623</td>\n",
              "      <td>35756071</td>\n",
              "      <td>contador publico(54)</td>\n",
              "      <td>44556937</td>\n",
              "      <td>yanet868@hotmail.com</td>\n",
              "      <td>hola,  quisiera obtener mi promedio o saber co...</td>\n",
              "      <td>lo calculas sumando las calificaciones de la o...</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Fecha  ...            Clase\n",
              "0  08-05-2019  ...  Otras Consultas\n",
              "1  08-08-2017  ...  Otras Consultas\n",
              "2  05-31-2017  ...  Otras Consultas\n",
              "3  02-05-2018  ...  Otras Consultas\n",
              "4  08-06-2016  ...  Otras Consultas\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaZUdGuZ-jL9"
      },
      "source": [
        "7. Descargo el módulo para las stopwords:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAfD72Qd-r-x"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72t0DR3M8dtx"
      },
      "source": [
        "8. Incorporo información de los embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5tBEnGc8iZ6",
        "outputId": "ad560ada-38fa-4b25-cf51-dac90d00cd79"
      },
      "source": [
        "count_esta=0\r\n",
        "count_no_esta=0\r\n",
        "\r\n",
        "docs_vectors = pd.DataFrame() # Se crea el dataframe para alojar el vector de pesos de cada documento\r\n",
        "stopwords = nltk.corpus.stopwords.words('spanish') # Se eliminan las palabras vacías\r\n",
        "for doc in df['Consulta'].str.lower().str.replace('[^a-z ]', ''): # Se limpia el texto (básico)\r\n",
        "    temp = pd.DataFrame()  # Se crea un datafame temporal para la vectorización de las palabras de cada documento\r\n",
        "    for word in doc.split(' '): # Se separa el doc en palabras\r\n",
        "        if word not in stopwords: # Se verifica que la palabra sea una una palabra vacía\r\n",
        "            try:\r\n",
        "                word_vec = embeddings[word] # Se verifica si la palabra está en los embeddings pre-entrenados\r\n",
        "                temp = temp.append(pd.Series(word_vec), ignore_index = True) # Si es así se incorpora el vector asociado al término\r\n",
        "                count_esta=count_esta+1 # Se contabiliza la existencia\r\n",
        "            except:\r\n",
        "                count_no_esta=count_no_esta+1 # Se contabiliza la NO existencia\r\n",
        "    doc_vector = temp.mean() # Se calcula el promedio para cada columna del dataframe asociado al documento anterior\r\n",
        "    docs_vectors = docs_vectors.append(doc_vector, ignore_index = True) # Se incorpora al dataframe definitivo el vector del documento\r\n",
        "docs_vectors.shape\r\n",
        "\r\n",
        "print(str(count_esta) + \" palabras de las consultas están en los embeddings pre-entrenados\")\r\n",
        "print(str(count_no_esta) + \" palabras de las consultas NO están en los embeddings pre-entrenados\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14452 están en los embeddings pre-entrenados\n",
            "3707 NO están en los embeddings pre-entrenados\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO1C0GJF_w5N"
      },
      "source": [
        "9. Incorporo la clase a los documentos vectorizados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "K_yKQ-Rl_V53",
        "outputId": "7a888e5a-7c3a-4198-e9b0-b4abfbd9d708"
      },
      "source": [
        "docs_vectors['Clase'] = df['Clase']\r\n",
        "docs_vectors.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>Clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.006431</td>\n",
              "      <td>-0.009342</td>\n",
              "      <td>0.019562</td>\n",
              "      <td>0.004289</td>\n",
              "      <td>0.011717</td>\n",
              "      <td>-0.029468</td>\n",
              "      <td>-0.013735</td>\n",
              "      <td>-0.016649</td>\n",
              "      <td>0.056541</td>\n",
              "      <td>0.013139</td>\n",
              "      <td>0.023258</td>\n",
              "      <td>-0.035717</td>\n",
              "      <td>-0.026671</td>\n",
              "      <td>-0.059891</td>\n",
              "      <td>0.039803</td>\n",
              "      <td>0.010155</td>\n",
              "      <td>-0.034154</td>\n",
              "      <td>0.027674</td>\n",
              "      <td>0.012747</td>\n",
              "      <td>0.042631</td>\n",
              "      <td>0.011165</td>\n",
              "      <td>-0.001284</td>\n",
              "      <td>0.026483</td>\n",
              "      <td>0.023362</td>\n",
              "      <td>0.004638</td>\n",
              "      <td>-0.061453</td>\n",
              "      <td>-0.034840</td>\n",
              "      <td>0.048891</td>\n",
              "      <td>-0.101722</td>\n",
              "      <td>0.053355</td>\n",
              "      <td>0.004811</td>\n",
              "      <td>-0.031459</td>\n",
              "      <td>-0.019401</td>\n",
              "      <td>-0.016548</td>\n",
              "      <td>0.001853</td>\n",
              "      <td>-0.031430</td>\n",
              "      <td>-0.027833</td>\n",
              "      <td>-0.021435</td>\n",
              "      <td>-0.022260</td>\n",
              "      <td>-0.016630</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049395</td>\n",
              "      <td>-0.033905</td>\n",
              "      <td>-0.013737</td>\n",
              "      <td>-0.026353</td>\n",
              "      <td>0.012318</td>\n",
              "      <td>-0.013092</td>\n",
              "      <td>0.008460</td>\n",
              "      <td>-0.027355</td>\n",
              "      <td>0.065042</td>\n",
              "      <td>-0.001175</td>\n",
              "      <td>0.062504</td>\n",
              "      <td>0.033647</td>\n",
              "      <td>0.001586</td>\n",
              "      <td>-0.006234</td>\n",
              "      <td>-0.030336</td>\n",
              "      <td>-0.051750</td>\n",
              "      <td>0.046526</td>\n",
              "      <td>-0.001611</td>\n",
              "      <td>0.021513</td>\n",
              "      <td>-0.015356</td>\n",
              "      <td>-0.022595</td>\n",
              "      <td>-0.016073</td>\n",
              "      <td>0.078183</td>\n",
              "      <td>0.040872</td>\n",
              "      <td>0.002164</td>\n",
              "      <td>0.036930</td>\n",
              "      <td>0.023710</td>\n",
              "      <td>-0.016223</td>\n",
              "      <td>-0.034074</td>\n",
              "      <td>-0.048917</td>\n",
              "      <td>0.018302</td>\n",
              "      <td>-0.035978</td>\n",
              "      <td>0.019141</td>\n",
              "      <td>-0.045450</td>\n",
              "      <td>-0.047646</td>\n",
              "      <td>-0.000216</td>\n",
              "      <td>-0.033998</td>\n",
              "      <td>-0.005368</td>\n",
              "      <td>0.034910</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002369</td>\n",
              "      <td>-0.015795</td>\n",
              "      <td>0.008516</td>\n",
              "      <td>-0.009306</td>\n",
              "      <td>-0.008713</td>\n",
              "      <td>-0.014095</td>\n",
              "      <td>-0.034005</td>\n",
              "      <td>-0.054447</td>\n",
              "      <td>0.054238</td>\n",
              "      <td>-0.011008</td>\n",
              "      <td>0.030823</td>\n",
              "      <td>-0.030618</td>\n",
              "      <td>-0.007342</td>\n",
              "      <td>-0.029420</td>\n",
              "      <td>0.008231</td>\n",
              "      <td>0.021344</td>\n",
              "      <td>-0.027991</td>\n",
              "      <td>-0.008710</td>\n",
              "      <td>0.005828</td>\n",
              "      <td>0.072837</td>\n",
              "      <td>0.005667</td>\n",
              "      <td>-0.018589</td>\n",
              "      <td>-0.012001</td>\n",
              "      <td>0.016404</td>\n",
              "      <td>-0.021190</td>\n",
              "      <td>-0.051351</td>\n",
              "      <td>-0.030322</td>\n",
              "      <td>0.044252</td>\n",
              "      <td>-0.074323</td>\n",
              "      <td>0.040171</td>\n",
              "      <td>-0.001171</td>\n",
              "      <td>-0.036806</td>\n",
              "      <td>-0.028483</td>\n",
              "      <td>-0.019692</td>\n",
              "      <td>-0.006190</td>\n",
              "      <td>-0.036091</td>\n",
              "      <td>-0.039644</td>\n",
              "      <td>-0.017939</td>\n",
              "      <td>-0.011261</td>\n",
              "      <td>-0.051703</td>\n",
              "      <td>...</td>\n",
              "      <td>0.082673</td>\n",
              "      <td>-0.029352</td>\n",
              "      <td>-0.018165</td>\n",
              "      <td>-0.026820</td>\n",
              "      <td>0.008090</td>\n",
              "      <td>0.006627</td>\n",
              "      <td>-0.019473</td>\n",
              "      <td>-0.030422</td>\n",
              "      <td>0.081443</td>\n",
              "      <td>-0.003396</td>\n",
              "      <td>0.036391</td>\n",
              "      <td>0.022918</td>\n",
              "      <td>0.012265</td>\n",
              "      <td>-0.012186</td>\n",
              "      <td>-0.022778</td>\n",
              "      <td>-0.011106</td>\n",
              "      <td>0.038096</td>\n",
              "      <td>-0.005326</td>\n",
              "      <td>-0.015675</td>\n",
              "      <td>-0.017562</td>\n",
              "      <td>-0.008405</td>\n",
              "      <td>-0.033801</td>\n",
              "      <td>0.061027</td>\n",
              "      <td>0.044871</td>\n",
              "      <td>-0.011784</td>\n",
              "      <td>0.020978</td>\n",
              "      <td>0.007014</td>\n",
              "      <td>-0.007709</td>\n",
              "      <td>-0.020980</td>\n",
              "      <td>-0.036263</td>\n",
              "      <td>0.000915</td>\n",
              "      <td>-0.036715</td>\n",
              "      <td>0.010582</td>\n",
              "      <td>-0.028672</td>\n",
              "      <td>-0.028392</td>\n",
              "      <td>-0.008085</td>\n",
              "      <td>-0.027400</td>\n",
              "      <td>0.007835</td>\n",
              "      <td>0.025657</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013886</td>\n",
              "      <td>-0.005830</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.018002</td>\n",
              "      <td>-0.001219</td>\n",
              "      <td>-0.014044</td>\n",
              "      <td>-0.013217</td>\n",
              "      <td>-0.025088</td>\n",
              "      <td>0.032274</td>\n",
              "      <td>0.022423</td>\n",
              "      <td>0.011219</td>\n",
              "      <td>-0.012576</td>\n",
              "      <td>-0.007802</td>\n",
              "      <td>-0.025862</td>\n",
              "      <td>0.031199</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>-0.042500</td>\n",
              "      <td>-0.024051</td>\n",
              "      <td>0.041442</td>\n",
              "      <td>0.033397</td>\n",
              "      <td>0.012645</td>\n",
              "      <td>0.006965</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>0.026033</td>\n",
              "      <td>-0.005464</td>\n",
              "      <td>-0.055565</td>\n",
              "      <td>-0.018448</td>\n",
              "      <td>0.037779</td>\n",
              "      <td>-0.054619</td>\n",
              "      <td>0.027261</td>\n",
              "      <td>0.028290</td>\n",
              "      <td>-0.026796</td>\n",
              "      <td>0.011784</td>\n",
              "      <td>-0.028710</td>\n",
              "      <td>0.014743</td>\n",
              "      <td>-0.042365</td>\n",
              "      <td>-0.039483</td>\n",
              "      <td>-0.023270</td>\n",
              "      <td>-0.034164</td>\n",
              "      <td>-0.010689</td>\n",
              "      <td>...</td>\n",
              "      <td>0.087875</td>\n",
              "      <td>-0.045448</td>\n",
              "      <td>-0.014048</td>\n",
              "      <td>-0.016818</td>\n",
              "      <td>-0.005466</td>\n",
              "      <td>-0.023313</td>\n",
              "      <td>-0.014992</td>\n",
              "      <td>-0.010460</td>\n",
              "      <td>0.084187</td>\n",
              "      <td>-0.008849</td>\n",
              "      <td>0.042013</td>\n",
              "      <td>0.025929</td>\n",
              "      <td>0.010893</td>\n",
              "      <td>0.019059</td>\n",
              "      <td>-0.022715</td>\n",
              "      <td>-0.051220</td>\n",
              "      <td>0.044968</td>\n",
              "      <td>0.013569</td>\n",
              "      <td>0.003081</td>\n",
              "      <td>-0.044446</td>\n",
              "      <td>-0.016212</td>\n",
              "      <td>0.032907</td>\n",
              "      <td>0.054954</td>\n",
              "      <td>0.042064</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>0.012225</td>\n",
              "      <td>0.008397</td>\n",
              "      <td>-0.002949</td>\n",
              "      <td>-0.040603</td>\n",
              "      <td>-0.019559</td>\n",
              "      <td>-0.016417</td>\n",
              "      <td>-0.033908</td>\n",
              "      <td>0.011083</td>\n",
              "      <td>-0.025650</td>\n",
              "      <td>-0.039967</td>\n",
              "      <td>-0.005116</td>\n",
              "      <td>-0.032856</td>\n",
              "      <td>0.016731</td>\n",
              "      <td>0.037949</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004119</td>\n",
              "      <td>-0.002486</td>\n",
              "      <td>0.044253</td>\n",
              "      <td>-0.009965</td>\n",
              "      <td>0.006727</td>\n",
              "      <td>-0.040330</td>\n",
              "      <td>-0.014752</td>\n",
              "      <td>-0.052373</td>\n",
              "      <td>0.038104</td>\n",
              "      <td>-0.005434</td>\n",
              "      <td>0.028855</td>\n",
              "      <td>-0.003339</td>\n",
              "      <td>-0.028225</td>\n",
              "      <td>-0.025469</td>\n",
              "      <td>0.028341</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>-0.027525</td>\n",
              "      <td>0.000942</td>\n",
              "      <td>-0.005540</td>\n",
              "      <td>0.031093</td>\n",
              "      <td>-0.012317</td>\n",
              "      <td>-0.001265</td>\n",
              "      <td>0.004829</td>\n",
              "      <td>0.045481</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>-0.060793</td>\n",
              "      <td>-0.017276</td>\n",
              "      <td>0.043502</td>\n",
              "      <td>-0.057966</td>\n",
              "      <td>0.060560</td>\n",
              "      <td>0.016564</td>\n",
              "      <td>-0.029534</td>\n",
              "      <td>-0.029159</td>\n",
              "      <td>0.009814</td>\n",
              "      <td>-0.000298</td>\n",
              "      <td>-0.033160</td>\n",
              "      <td>-0.042544</td>\n",
              "      <td>-0.015639</td>\n",
              "      <td>-0.004029</td>\n",
              "      <td>-0.037405</td>\n",
              "      <td>...</td>\n",
              "      <td>0.092389</td>\n",
              "      <td>-0.037960</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>-0.032974</td>\n",
              "      <td>-0.005161</td>\n",
              "      <td>-0.008020</td>\n",
              "      <td>-0.008256</td>\n",
              "      <td>-0.057044</td>\n",
              "      <td>0.043194</td>\n",
              "      <td>0.037280</td>\n",
              "      <td>0.032843</td>\n",
              "      <td>0.026802</td>\n",
              "      <td>0.022840</td>\n",
              "      <td>0.002081</td>\n",
              "      <td>-0.028819</td>\n",
              "      <td>-0.019784</td>\n",
              "      <td>0.058049</td>\n",
              "      <td>0.013038</td>\n",
              "      <td>-0.015701</td>\n",
              "      <td>-0.027065</td>\n",
              "      <td>-0.004788</td>\n",
              "      <td>-0.024877</td>\n",
              "      <td>0.025360</td>\n",
              "      <td>0.047831</td>\n",
              "      <td>-0.041555</td>\n",
              "      <td>0.039662</td>\n",
              "      <td>0.014778</td>\n",
              "      <td>-0.007117</td>\n",
              "      <td>-0.014467</td>\n",
              "      <td>-0.058065</td>\n",
              "      <td>0.022331</td>\n",
              "      <td>-0.004518</td>\n",
              "      <td>-0.006239</td>\n",
              "      <td>-0.033535</td>\n",
              "      <td>-0.030493</td>\n",
              "      <td>0.005118</td>\n",
              "      <td>-0.014152</td>\n",
              "      <td>-0.017904</td>\n",
              "      <td>0.024175</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.013964</td>\n",
              "      <td>-0.007655</td>\n",
              "      <td>0.023141</td>\n",
              "      <td>0.005440</td>\n",
              "      <td>0.008330</td>\n",
              "      <td>-0.023091</td>\n",
              "      <td>-0.009174</td>\n",
              "      <td>-0.019315</td>\n",
              "      <td>0.035563</td>\n",
              "      <td>0.016122</td>\n",
              "      <td>0.048655</td>\n",
              "      <td>-0.048970</td>\n",
              "      <td>-0.021151</td>\n",
              "      <td>-0.065668</td>\n",
              "      <td>0.020106</td>\n",
              "      <td>0.005968</td>\n",
              "      <td>-0.027917</td>\n",
              "      <td>0.003851</td>\n",
              "      <td>0.037852</td>\n",
              "      <td>0.053073</td>\n",
              "      <td>0.017134</td>\n",
              "      <td>0.016696</td>\n",
              "      <td>0.009764</td>\n",
              "      <td>0.049485</td>\n",
              "      <td>0.009628</td>\n",
              "      <td>-0.070680</td>\n",
              "      <td>-0.046810</td>\n",
              "      <td>0.047627</td>\n",
              "      <td>-0.118441</td>\n",
              "      <td>0.035296</td>\n",
              "      <td>0.007232</td>\n",
              "      <td>-0.039070</td>\n",
              "      <td>-0.024893</td>\n",
              "      <td>-0.040426</td>\n",
              "      <td>-0.009545</td>\n",
              "      <td>-0.033450</td>\n",
              "      <td>-0.031191</td>\n",
              "      <td>-0.006677</td>\n",
              "      <td>-0.008112</td>\n",
              "      <td>-0.009537</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048867</td>\n",
              "      <td>-0.059556</td>\n",
              "      <td>-0.000089</td>\n",
              "      <td>-0.015920</td>\n",
              "      <td>0.012154</td>\n",
              "      <td>-0.019730</td>\n",
              "      <td>0.023718</td>\n",
              "      <td>-0.028236</td>\n",
              "      <td>0.077646</td>\n",
              "      <td>0.006075</td>\n",
              "      <td>0.061348</td>\n",
              "      <td>0.047220</td>\n",
              "      <td>0.024820</td>\n",
              "      <td>-0.009576</td>\n",
              "      <td>-0.023623</td>\n",
              "      <td>-0.007919</td>\n",
              "      <td>0.073704</td>\n",
              "      <td>0.053593</td>\n",
              "      <td>0.039357</td>\n",
              "      <td>-0.007499</td>\n",
              "      <td>-0.046087</td>\n",
              "      <td>-0.016846</td>\n",
              "      <td>0.047867</td>\n",
              "      <td>0.024816</td>\n",
              "      <td>-0.014027</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.013614</td>\n",
              "      <td>-0.000791</td>\n",
              "      <td>-0.015289</td>\n",
              "      <td>-0.061121</td>\n",
              "      <td>-0.005310</td>\n",
              "      <td>-0.039734</td>\n",
              "      <td>0.005953</td>\n",
              "      <td>-0.027858</td>\n",
              "      <td>-0.068998</td>\n",
              "      <td>-0.004713</td>\n",
              "      <td>-0.042710</td>\n",
              "      <td>0.008178</td>\n",
              "      <td>0.010627</td>\n",
              "      <td>Otras Consultas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 301 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       298       299            Clase\n",
              "0  0.006431 -0.009342  0.019562  ... -0.005368  0.034910  Otras Consultas\n",
              "1  0.002369 -0.015795  0.008516  ...  0.007835  0.025657  Otras Consultas\n",
              "2  0.013886 -0.005830  0.022338  ...  0.016731  0.037949  Otras Consultas\n",
              "3  0.004119 -0.002486  0.044253  ... -0.017904  0.024175  Otras Consultas\n",
              "4 -0.013964 -0.007655  0.023141  ...  0.008178  0.010627  Otras Consultas\n",
              "\n",
              "[5 rows x 301 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAzxoiel_1ZF"
      },
      "source": [
        "10. Separo en training y testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJXnQbwf_uG4",
        "outputId": "cd985f5e-2a44-4242-db20-72ef6a59c13c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train_x, test_x, train_y, test_y = train_test_split(docs_vectors.drop('Clase', axis = 1),\r\n",
        "                                                   docs_vectors['Clase'],\r\n",
        "                                                   test_size = 0.2,\r\n",
        "                                                   random_state = 1)\r\n",
        "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((800, 300), (800,), (200, 300), (200,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh6E5i0I_98V"
      },
      "source": [
        "11. Entreno el clasificador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4GQ3QdjAAG2",
        "outputId": "0b5260cb-42d2-4a0a-cd08-8f443172b80a"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "model = AdaBoostClassifier(n_estimators=800, random_state = 1)\r\n",
        "model.fit(train_x, train_y)\r\n",
        "test_pred = model.predict(test_x)\r\n",
        "\r\n",
        "accuracy_score(test_y, test_pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utwfXOA2Gbfn",
        "outputId": "621f8cf6-6dd9-4591-8a37-0bb15fc3a2b1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "modelo_regresion = LogisticRegression()\r\n",
        "modelo_regresion.fit(train_x, train_y)\r\n",
        "\r\n",
        "# Realizo la predicción de y con el x_test\r\n",
        "test_pred = modelo_regresion.predict(test_x)\r\n",
        "\r\n",
        "accuracy_score(test_y, test_pred)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdGIcvlSy43x"
      },
      "source": [
        "## Referencias\r\n",
        "- <a href=\"https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\">Multi-Class Text Classification Model Comparison and Selection</a>\r\n",
        "- <a href=\"https://unipython.com/como-desarrollar-embeddings-incrustaciones-de-palabras-con-gensim/\">Cómo desarrollar embeddings (incrustraciones) de palabras con GENSIM</a>\r\n",
        "- <a href=\"https://www.kaggle.com/ananyabioinfo/text-classification-using-word2vec\">Text classification using word2vec</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbHrhYDxzEaF"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}