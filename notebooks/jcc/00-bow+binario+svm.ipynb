{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00-bow+binario+svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jcc/00-bow%2Bbinario%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Baseline JCC: BoW+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos sobre la estrategia de representación y técnica de aprendizaje *baseline* utilizada para las JCC de  la Universidad Nacional de La Plata.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf",
        "outputId": "f96d5168-9f0f-43de-db4c-0800f7c397a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cargamos el archivo con las consultas para entrenamiento que está en Github\n",
        "from os import path\n",
        "\n",
        "# En caso que no esté el archivo en Colab lo traigo\n",
        "if not(path.exists('correos-train-80.csv')):\n",
        "  !wget https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/correos-train-80.csv  \n",
        "\n",
        "# Leemos el archivo en un dataframe\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv('correos-train-80.csv')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 10:56:47--  https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/correos-train-80.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223169 (218K) [text/plain]\n",
            "Saving to: ‘correos-train-80.csv’\n",
            "\n",
            "correos-train-80.cs 100%[===================>] 217.94K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-03-19 10:56:47 (6.77 MB/s) - ‘correos-train-80.csv’ saved [223169/223169]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhL2MmCje-Pn"
      },
      "source": [
        "# Me traigo las etiquetas de las clases de train_test_data.ipynb\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "etiquetas_clases = np.array(['Boleto Universitario', \r\n",
        "                    'Cambio de Carrera', \r\n",
        "                    'Cambio de Comisión',\r\n",
        "                    'Carga de Notas', \r\n",
        "                    'Certificados Web', \r\n",
        "                    'Consulta por Equivalencias',\r\n",
        "                    'Consulta por Legajo', \r\n",
        "                    'Consulta sobre Título Universitario',\r\n",
        "                    'Cursadas', \r\n",
        "                    'Datos Personales', \r\n",
        "                    'Exámenes',\r\n",
        "                    'Ingreso a la Universidad',\r\n",
        "                    'Inscripción a Cursadas',\r\n",
        "                    'Pedido de Certificados',\r\n",
        "                    'Problemas con la Clave',\r\n",
        "                    'Reincorporación', \r\n",
        "                    'Requisitos de Ingreso',\r\n",
        "                    'Simultaneidad de Carreras', \r\n",
        "                    'Situación Académica',\r\n",
        "                    'Vacunas Enfermería'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "3f875740-0d01-47d4-f596-1d66b1b262d7"
      },
      "source": [
        "# Transformamos todas las Clases minoritarias (Puedo ir variando la cantidad de clases que derivo a la Clase \"Otras Consultas\")\r\n",
        "cantidad_clases=4\r\n",
        "\r\n",
        "clases = df_train.clase.value_counts()\r\n",
        "clases_minoritarias = clases.iloc[cantidad_clases-1:].keys().to_list()\r\n",
        "clases_minoritarias\r\n",
        "\r\n",
        "# Agrego a las etiquetas la etiqueta \"Otras Consultas\"\r\n",
        "etiquetas_clases = np.append(etiquetas_clases, \"Otras Consultas\")\r\n",
        "\r\n",
        "# Genero una nueva clave de clases para \"Otras Consultas\" a modo de agrupar las que poseen menos apariciones\r\n",
        "df_train.clase[df_train['clase'].isin(clases_minoritarias)] = np.where(etiquetas_clases == \"Otras Consultas\")[0]\r\n",
        "\r\n",
        "\r\n",
        "# Clases balanceadas\r\n",
        "df_train.clase.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20    320\n",
              "0     192\n",
              "11    185\n",
              "16    103\n",
              "Name: clase, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7IG6gK9Ogeo"
      },
      "source": [
        "# Me guardo los atributos, excepto la clase en x\n",
        "y_train = df_train['clase'].to_numpy()\n",
        "x_train = df_train.drop(['clase'], axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Generamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EfgucE-4KUt",
        "outputId": "29b15fda-fca1-4d2b-a879-bca2bf8964e6"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "# Defino la feature y la transformación a aplicar en el texto\r\n",
        "text_features = 'Consulta'\r\n",
        "text_transformer = CountVectorizer()\r\n",
        "\r\n",
        "# Defino la transformación\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('text', text_transformer, text_features)\r\n",
        "        ], remainder='passthrough')\r\n",
        "\r\n",
        "# Combino la transformación con el pipeline\r\n",
        "model_pipe = Pipeline([('preprocessor', preprocessor),\r\n",
        "                       ('svm', SVC())])\r\n",
        "\r\n",
        "# Defino los parámetros para GridSearchCV\r\n",
        "parameters=[\r\n",
        "        {'preprocessor__text__binary': [True, False],\r\n",
        "         'preprocessor__text__analyzer': ['char'],\r\n",
        "         'preprocessor__text__ngram_range': ((3, 3), (4, 7), (3, 4)),\r\n",
        "#         'preprocessor__text__strip_accents': ['unicode'],     \r\n",
        "#         'preprocessor__text__max_features':[500, 1000, 1500, 3000],\r\n",
        "#         'svm__C': [0.1, 1, 10, 100, 1000],  \r\n",
        "         'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "#         'svm__class_weight': [None, 'balanced'],\r\n",
        "#         'svm__kernel': ['rbf', 'linear', 'poly', 'rbf', 'sigmoid']\r\n",
        "    }\r\n",
        "]\r\n",
        "\r\n",
        "# Instancio y \"entreno\" el GridSearchCV\r\n",
        "grid_search=GridSearchCV(model_pipe, param_grid=parameters, cv=None, n_jobs=-1, verbose=3)\r\n",
        "grid_search.fit(x_train, y_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   34.6s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessor',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='passthrough',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('text',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=...\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0.001, verbose=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid=[{'preprocessor__text__analyzer': ['char'],\n",
              "                          'preprocessor__text__binary': [True, False],\n",
              "                          'preprocessor__text__ngram_range': ((3, 3), (4, 7),\n",
              "                                                              (3, 4)),\n",
              "                          'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYcaSAyarqAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67d99d1-1389-4afa-de36-1c8f148c80da"
      },
      "source": [
        "# Imprimo los mejores parámetros encontrados por GridSearchCV\r\n",
        "print(grid_search.best_params_) \r\n",
        "  \r\n",
        "# Imprimo el modelo después del ajuste de hiperparámetros\r\n",
        "print(grid_search.best_estimator_) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'preprocessor__text__analyzer': 'char', 'preprocessor__text__binary': False, 'preprocessor__text__ngram_range': (4, 7), 'svm__gamma': 0.001}\n",
            "Pipeline(memory=None,\n",
            "         steps=[('preprocessor',\n",
            "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
            "                                   sparse_threshold=0.3,\n",
            "                                   transformer_weights=None,\n",
            "                                   transformers=[('text',\n",
            "                                                  CountVectorizer(analyzer='char',\n",
            "                                                                  binary=False,\n",
            "                                                                  decode_error='strict',\n",
            "                                                                  dtype=<class 'numpy.int64'>,\n",
            "                                                                  encoding='utf-8',\n",
            "                                                                  input='content',\n",
            "                                                                  lowercase=True,\n",
            "                                                                  max_df=1.0,\n",
            "                                                                  max_features=None,\n",
            "                                                                  min_df=1,\n",
            "                                                                  ngra...\n",
            "                                                                  strip_accents=None,\n",
            "                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                                                  tokenizer=None,\n",
            "                                                                  vocabulary=None),\n",
            "                                                  'Consulta')],\n",
            "                                   verbose=False)),\n",
            "                ('svm',\n",
            "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
            "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
            "                     gamma=0.001, kernel='rbf', max_iter=-1, probability=False,\n",
            "                     random_state=None, shrinking=True, tol=0.001,\n",
            "                     verbose=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZmyNn__8ML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9540c8b1-1e0d-4892-bc98-1acdd13f2ef0"
      },
      "source": [
        "# Me autentico en Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('drive')\r\n",
        "\r\n",
        "# Paso los resultados y el accuracy a un dataframe\r\n",
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]), pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\r\n",
        "\r\n",
        "# Los guardo en data_results.csv en mi Drive\r\n",
        "results.to_csv('data_results.csv')\r\n",
        "!cp data_results.csv \"drive/My Drive/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQsimiaokvn8",
        "outputId": "ac566798-06df-498a-d7dc-b8d43f385065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Levanto las instancias de testeo\r\n",
        "\r\n",
        "# En caso que no esté el archivo en Colab lo traigo\r\n",
        "if not(path.exists('correos-test-20.csv')):\r\n",
        "  !wget https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/correos-test-20.csv  \r\n",
        "\r\n",
        "# Leemos el archivo en un dataframe\r\n",
        "import pandas as pd\r\n",
        "df_test = pd.read_csv('correos-test-20.csv')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 11:01:49--  https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/correos-test-20.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58146 (57K) [text/plain]\n",
            "Saving to: ‘correos-test-20.csv’\n",
            "\n",
            "correos-test-20.csv 100%[===================>]  56.78K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-03-19 11:01:49 (4.31 MB/s) - ‘correos-test-20.csv’ saved [58146/58146]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6s6BUHnlJZ5",
        "outputId": "8cfd87a0-2f4b-4b64-8b2b-e1482990f5c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Balanceo las clases de testing\r\n",
        "\r\n",
        "clases_test = df_test.clase.value_counts()\r\n",
        "clases_minoritarias_test = clases_test.iloc[cantidad_clases-1:].keys().to_list()\r\n",
        "clases_minoritarias_test\r\n",
        "\r\n",
        "# Genero una nueva clave de clases para \"Otras Consultas\" a modo de agrupar las que poseen menos apariciones\r\n",
        "df_test.clase[df_test['clase'].isin(clases_minoritarias)] = np.where(etiquetas_clases == \"Otras Consultas\")[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20    79\n",
              "0     48\n",
              "11    47\n",
              "16    26\n",
              "Name: clase, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJheGvyWl7bW"
      },
      "source": [
        "# Me guardo los atributos, excepto la clase en x\r\n",
        "y_test = df_test['clase'].to_numpy()\r\n",
        "x_test = df_test.drop(['clase'], axis=1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq3A5ecT19O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2caa5f3-b085-40d7-d00d-a6d3069de0a5"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix \r\n",
        "\r\n",
        "# Se realizan las predicciones sobre el conjunto de validación\r\n",
        "grid_predictions = grid_search.predict(x_test) \r\n",
        "\r\n",
        "# Se imprime el reporte de clasificación\r\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80        48\n",
            "          11       0.76      0.34      0.47        47\n",
            "          16       1.00      0.15      0.27        26\n",
            "          20       0.52      0.94      0.67        79\n",
            "\n",
            "    accuracy                           0.63       200\n",
            "   macro avg       0.82      0.52      0.55       200\n",
            "weighted avg       0.75      0.63      0.60       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "# Referencias\r\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\r\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}