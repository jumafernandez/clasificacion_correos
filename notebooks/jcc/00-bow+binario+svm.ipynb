{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00-bow+binario+svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jcc/00-bow%2Bbinario%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Baseline JCC: BoW+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos sobre la estrategia de representación y técnica de aprendizaje *baseline* utilizada para las JCC de  la Universidad Nacional de La Plata.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7883a984-918f-439f-8857-f49e4478e307"
      },
      "source": [
        "# Cargamos el archivo con las consultas que está en Github\n",
        "from os import path\n",
        "\n",
        "# En caso que no esté el archivo en Colab lo traigo\n",
        "if not(path.exists('03-Correos_variables_estaticas.csv')):\n",
        "  !wget https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/03-Correos_variables_estaticas.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-10 20:06:25--  https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/03-Correos_variables_estaticas.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 303767 (297K) [text/plain]\n",
            "Saving to: ‘03-Correos_variables_estaticas.csv’\n",
            "\n",
            "03-Correos_variable 100%[===================>] 296.65K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-03-10 20:06:25 (7.56 MB/s) - ‘03-Correos_variables_estaticas.csv’ saved [303767/303767]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-MMYgBfpEA"
      },
      "source": [
        "# Leemos el archivo en un dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv('03-Correos_variables_estaticas.csv', delimiter=\"|\")\n",
        "\n",
        "# Se transforma proveedor_correo a numerico\n",
        "from sklearn import preprocessing\n",
        "le_correo = preprocessing.LabelEncoder()\n",
        "df['proveedor_correo'] = le_correo.fit_transform(df['proveedor_correo'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4URhjJvm0y",
        "outputId": "fb978a69-49b0-4a25-e7f8-1328f3e158bc"
      },
      "source": [
        "# Me guardo los atributos, excepto la clase en x\r\n",
        "x = df.drop(['Clase'], axis=1)\r\n",
        "x.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Consulta', 'dia_semana', 'semana_del_mes', 'mes', 'cuatrimestre',\n",
              "       'anio', 'hora_discretizada', 'dni_discretizado', 'legajo_discretizado',\n",
              "       'posee_legajo', 'posee_telefono', 'carrera_valor', 'proveedor_correo',\n",
              "       'cantidad_caracteres', 'proporcion_mayusculas', 'proporcion_letras',\n",
              "       'cantidad_tildes', 'cantidad_palabras', 'cantidad_palabras_cortas',\n",
              "       'proporcion_palabras_distintas', 'frecuencia_signos_puntuacion',\n",
              "       'cantidad_oraciones', 'utiliza_codigo_asignatura'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "60e06ab0-689d-400e-9b93-87a8108c7d12"
      },
      "source": [
        "# Transformamos todas las Clases minoritarias (Puedo ir variando la cantidad de clases que derivo a la Clase \"Otras Consultas\")\r\n",
        "cantidad_clases=4\r\n",
        "\r\n",
        "clases = df.Clase.value_counts()\r\n",
        "clases_minoritarias = clases.iloc[cantidad_clases:].keys().to_list()\r\n",
        "\r\n",
        "df.Clase[df['Clase'].isin(clases_minoritarias)] = \"Otras Consultas\"\r\n",
        "\r\n",
        "# Clases balanceadas\r\n",
        "df.Clase.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Otras Consultas             330\n",
              "Boleto Universitario        240\n",
              "Ingreso a la Universidad    232\n",
              "Requisitos de Ingreso       129\n",
              "Pedido de Certificados       69\n",
              "Name: Clase, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMQlwGgdL_-p"
      },
      "source": [
        "# Se numeriza la clase\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# Me quedo con las clases numerizadas\n",
        "y=le.fit_transform(df['Clase'])\n",
        "\n",
        "# Por otro lado me guardo las etiquetas de las clases\n",
        "target_names=le.classes_"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7IG6gK9Ogeo"
      },
      "source": [
        "# Separo datos de entrenamiento y testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separo en 80-20 entrenamiento/validación y testeo\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Generamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EfgucE-4KUt",
        "outputId": "e2add3b4-1426-4cdb-ccb2-b447a0b4438e"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "# Defino la feature y la transformación a aplicar en el texto\r\n",
        "text_features = 'Consulta'\r\n",
        "text_transformer = CountVectorizer()\r\n",
        "\r\n",
        "# Defino la transformación\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('text', text_transformer, text_features)\r\n",
        "        ], remainder='passthrough')\r\n",
        "\r\n",
        "# Combino la transformación con el pipeline\r\n",
        "model_pipe = Pipeline([('preprocessor', preprocessor),\r\n",
        "                       ('svm', SVC())])\r\n",
        "\r\n",
        "# Defino los parámetros para GridSearchCV\r\n",
        "parameters=[\r\n",
        "        {'preprocessor__text__binary': [True, False],\r\n",
        "         'preprocessor__text__analyzer': ['char'],\r\n",
        "         'preprocessor__text__ngram_range': ((3, 3), (4, 7), (3, 4)),\r\n",
        "         'preprocessor__text__strip_accents': ['unicode'],     \r\n",
        "         'preprocessor__text__max_features':[500, 1000, 1500, 3000],\r\n",
        "         'svm__C': [0.1, 1, 10, 100, 1000],  \r\n",
        "         'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "         'svm__class_weight': [None, 'balanced'],\r\n",
        "         'svm__kernel': ['rbf', 'linear', 'poly', 'rbf', 'sigmoid']\r\n",
        "    }\r\n",
        "]\r\n",
        "\r\n",
        "# Instancio y \"entreno\" el GridSearchCV\r\n",
        "grid_search=GridSearchCV(model_pipe, param_grid=parameters, cv=None, n_jobs=-1, verbose=3)\r\n",
        "grid_search.fit(x_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   30.1s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  3.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessor',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='passthrough',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('text',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=...\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0.001, verbose=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid=[{'preprocessor__text__analyzer': ['char'],\n",
              "                          'preprocessor__text__binary': [True, False],\n",
              "                          'preprocessor__text__ngram_range': ((3, 3), (4, 7),\n",
              "                                                              (3, 4)),\n",
              "                          'svm__C': [0.1, 1, 10, 100, 1000]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYcaSAyarqAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685618ec-7826-4424-b2d2-3b6dca424e95"
      },
      "source": [
        "# Imprimo los mejores parámetros encontrados por GridSearchCV\r\n",
        "print(grid_search.best_params_) \r\n",
        "  \r\n",
        "# Imprimo el modelo después del ajuste de hiperparámetros\r\n",
        "print(grid_search.best_estimator_) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'preprocessor__text__analyzer': 'char', 'preprocessor__text__binary': False, 'preprocessor__text__ngram_range': (4, 7), 'svm__C': 1000}\n",
            "Pipeline(memory=None,\n",
            "         steps=[('preprocessor',\n",
            "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
            "                                   sparse_threshold=0.3,\n",
            "                                   transformer_weights=None,\n",
            "                                   transformers=[('text',\n",
            "                                                  CountVectorizer(analyzer='char',\n",
            "                                                                  binary=False,\n",
            "                                                                  decode_error='strict',\n",
            "                                                                  dtype=<class 'numpy.int64'>,\n",
            "                                                                  encoding='utf-8',\n",
            "                                                                  input='content',\n",
            "                                                                  lowercase=True,\n",
            "                                                                  max_df=1.0,\n",
            "                                                                  max_features=None,\n",
            "                                                                  min_df=1,\n",
            "                                                                  ngra...\n",
            "                                                                  strip_accents=None,\n",
            "                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                                                  tokenizer=None,\n",
            "                                                                  vocabulary=None),\n",
            "                                                  'Consulta')],\n",
            "                                   verbose=False)),\n",
            "                ('svm',\n",
            "                 SVC(C=1000, break_ties=False, cache_size=200,\n",
            "                     class_weight=None, coef0=0.0,\n",
            "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
            "                     kernel='rbf', max_iter=-1, probability=False,\n",
            "                     random_state=None, shrinking=True, tol=0.001,\n",
            "                     verbose=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq3A5ecT19O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91dab2d5-9582-4479-f462-c55f990bd7af"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix \r\n",
        "\r\n",
        "# Se realizan las predicciones sobre el conjunto de validación\r\n",
        "grid_predictions = grid_search.predict(x_test) \r\n",
        "\r\n",
        "# Se imprime el reporte de clasificación\r\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.87      0.93        47\n",
            "           1       0.97      0.76      0.85        50\n",
            "           2       0.65      0.97      0.78        66\n",
            "           3       1.00      0.57      0.73        21\n",
            "           4       0.78      0.44      0.56        16\n",
            "\n",
            "    accuracy                           0.81       200\n",
            "   macro avg       0.88      0.72      0.77       200\n",
            "weighted avg       0.86      0.81      0.81       200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "# Referencias\r\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\r\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}