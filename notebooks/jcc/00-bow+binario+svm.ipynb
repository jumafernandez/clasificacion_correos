{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "00-bow+binario+svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jcc/00-bow%2Bbinario%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Baseline JCC: BoW+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos sobre la estrategia de representación y técnica de aprendizaje *baseline* utilizada para las JCC de  la Universidad Nacional de La Plata.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "# Cargamos el archivo con las consultas que está en Github\n",
        "from os import path\n",
        "\n",
        "# En caso que no esté el archivo en Colab lo traigo\n",
        "if not(path.exists('03-Correos_variables_estaticas.csv')):\n",
        "  !wget https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/03-Correos_variables_estaticas.csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-MMYgBfpEA"
      },
      "source": [
        "# Leemos el archivo en un dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv('03-Correos_variables_estaticas.csv', delimiter=\"|\")\n",
        "\n",
        "# Se transforma proveedor_correo a numerico\n",
        "from sklearn import preprocessing\n",
        "le_correo = preprocessing.LabelEncoder()\n",
        "df['proveedor_correo'] = le_correo.fit_transform(df['proveedor_correo'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg4URhjJvm0y",
        "outputId": "d497d7d0-8a19-46b0-e202-1482e709bdb1"
      },
      "source": [
        "# Me guardo los atributos, excepto la clase en x\r\n",
        "x = df.drop(['Clase'], axis=1)\r\n",
        "x.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Consulta', 'dia_semana', 'semana_del_mes', 'mes', 'cuatrimestre',\n",
              "       'anio', 'hora_discretizada', 'dni_discretizado', 'legajo_discretizado',\n",
              "       'posee_legajo', 'posee_telefono', 'carrera_valor', 'proveedor_correo',\n",
              "       'cantidad_caracteres', 'proporcion_mayusculas', 'proporcion_letras',\n",
              "       'cantidad_tildes', 'cantidad_palabras', 'cantidad_palabras_cortas',\n",
              "       'proporcion_palabras_distintas', 'frecuencia_signos_puntuacion',\n",
              "       'cantidad_oraciones', 'utiliza_codigo_asignatura'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "6fb27e36-3fca-4a98-8457-47e222b776f7"
      },
      "source": [
        "# Transformamos todas las Clases minoritarias (Puedo ir variando la cantidad de clases que derivo a la Clase \"Otras Consultas\")\r\n",
        "cantidad_clases=4\r\n",
        "\r\n",
        "clases = df.Clase.value_counts()\r\n",
        "clases_minoritarias = clases.iloc[cantidad_clases:].keys().to_list()\r\n",
        "\r\n",
        "df.Clase[df['Clase'].isin(clases_minoritarias)] = \"Otras Consultas\"\r\n",
        "\r\n",
        "# Clases balanceadas\r\n",
        "df.Clase.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Otras Consultas             330\n",
              "Boleto Universitario        240\n",
              "Ingreso a la Universidad    232\n",
              "Requisitos de Ingreso       129\n",
              "Pedido de Certificados       69\n",
              "Name: Clase, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMQlwGgdL_-p"
      },
      "source": [
        "# Se numeriza la clase\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "# Me quedo con las clases numerizadas\n",
        "y=le.fit_transform(df['Clase'])\n",
        "\n",
        "# Por otro lado me guardo las etiquetas de las clases\n",
        "target_names=le.classes_"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7IG6gK9Ogeo"
      },
      "source": [
        "# Separo datos de entrenamiento y testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separo en 80-20 entrenamiento/validación y testeo\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Generamos el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EfgucE-4KUt",
        "outputId": "e8301e64-316c-4380-fc65-f95287c8f28e"
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "# Defino la feature y la transformación a aplicar en el texto\r\n",
        "text_features = 'Consulta'\r\n",
        "text_transformer = CountVectorizer()\r\n",
        "\r\n",
        "# Defino la transformación\r\n",
        "preprocessor = ColumnTransformer(\r\n",
        "    transformers=[\r\n",
        "        ('text', text_transformer, text_features)\r\n",
        "        ], remainder='passthrough')\r\n",
        "\r\n",
        "# Combino la transformación con el pipeline\r\n",
        "model_pipe = Pipeline([('preprocessor', preprocessor),\r\n",
        "                       ('svm', SVC())])\r\n",
        "\r\n",
        "# Defino los parámetros para GridSearchCV\r\n",
        "parameters=[\r\n",
        "        {'preprocessor__text__binary': [True, False],\r\n",
        "         'preprocessor__text__analyzer': ['char'],\r\n",
        "         'preprocessor__text__ngram_range': ((3, 3), (4, 7), (3, 4)),\r\n",
        "         'preprocessor__text__strip_accents': ['unicode'],     \r\n",
        "         'preprocessor__text__max_features':[500, 1000, 1500, 3000],\r\n",
        "         'svm__C': [0.1, 1, 10, 100, 1000],  \r\n",
        "         'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "         'svm__class_weight': [None, 'balanced'],\r\n",
        "         'svm__kernel': ['rbf', 'linear', 'poly', 'rbf', 'sigmoid']\r\n",
        "    }\r\n",
        "]\r\n",
        "\r\n",
        "# Instancio y \"entreno\" el GridSearchCV\r\n",
        "grid_search=GridSearchCV(model_pipe, param_grid=parameters, cv=None, n_jobs=-1, verbose=3)\r\n",
        "grid_search.fit(x_train, y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   48.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('preprocessor',\n",
              "                                        ColumnTransformer(n_jobs=None,\n",
              "                                                          remainder='passthrough',\n",
              "                                                          sparse_threshold=0.3,\n",
              "                                                          transformer_weights=None,\n",
              "                                                          transformers=[('text',\n",
              "                                                                         CountVectorizer(analyzer='word',\n",
              "                                                                                         binary=False,\n",
              "                                                                                         decode_error='strict',\n",
              "                                                                                         dtype=<class 'numpy.int64'>,\n",
              "                                                                                         encoding='utf-8',\n",
              "                                                                                         input='content',\n",
              "                                                                                         lowercase=...\n",
              "                                            probability=False,\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0.001, verbose=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid=[{'preprocessor__text__analyzer': ['char'],\n",
              "                          'preprocessor__text__binary': [True, False],\n",
              "                          'preprocessor__text__ngram_range': ((3, 3), (4, 7),\n",
              "                                                              (3, 4))}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYcaSAyarqAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98d6b3b-bcc7-44e8-d8df-8b0abde80bb7"
      },
      "source": [
        "# Imprimo los mejores parámetros encontrados por GridSearchCV\r\n",
        "print(grid_search.best_params_) \r\n",
        "  \r\n",
        "# Imprimo el modelo después del ajuste de hiperparámetros\r\n",
        "print(grid_search.best_estimator_) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'preprocessor__text__analyzer': 'char', 'preprocessor__text__binary': True, 'preprocessor__text__ngram_range': (3, 3)}\n",
            "Pipeline(memory=None,\n",
            "         steps=[('preprocessor',\n",
            "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
            "                                   sparse_threshold=0.3,\n",
            "                                   transformer_weights=None,\n",
            "                                   transformers=[('text',\n",
            "                                                  CountVectorizer(analyzer='char',\n",
            "                                                                  binary=True,\n",
            "                                                                  decode_error='strict',\n",
            "                                                                  dtype=<class 'numpy.int64'>,\n",
            "                                                                  encoding='utf-8',\n",
            "                                                                  input='content',\n",
            "                                                                  lowercase=True,\n",
            "                                                                  max_df=1.0,\n",
            "                                                                  max_features=None,\n",
            "                                                                  min_df=1,\n",
            "                                                                  ngram...\n",
            "                                                                  strip_accents=None,\n",
            "                                                                  token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                                                                  tokenizer=None,\n",
            "                                                                  vocabulary=None),\n",
            "                                                  'Consulta')],\n",
            "                                   verbose=False)),\n",
            "                ('svm',\n",
            "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
            "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
            "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                     probability=False, random_state=None, shrinking=True,\n",
            "                     tol=0.001, verbose=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nZmyNn__8ML",
        "outputId": "17e284ee-7965-4f42-f683-0bf0ff060b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Me autentico en Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('drive')\r\n",
        "\r\n",
        "# Paso los resultados y el accuracy a un dataframe\r\n",
        "results = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]), pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\r\n",
        "\r\n",
        "# Los guardo en data_results.csv en mi Drive\r\n",
        "results.to_csv('data_results.csv')\r\n",
        "!cp data_results.csv \"drive/My Drive/\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq3A5ecT19O9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edfdaf2-6f60-4911-a7e2-65fe1755e442"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix \r\n",
        "\r\n",
        "# Se realizan las predicciones sobre el conjunto de validación\r\n",
        "grid_predictions = grid_search.predict(x_test) \r\n",
        "\r\n",
        "# Se imprime el reporte de clasificación\r\n",
        "print(classification_report(y_test, grid_predictions))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        47\n",
            "           1       0.00      0.00      0.00        50\n",
            "           2       0.33      1.00      0.50        66\n",
            "           3       0.00      0.00      0.00        21\n",
            "           4       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.33       200\n",
            "   macro avg       0.07      0.20      0.10       200\n",
            "weighted avg       0.11      0.33      0.16       200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "# Referencias\r\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\r\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}