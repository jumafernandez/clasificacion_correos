{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-bow+binario+svm.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumafernandez/clasificacion_correos/blob/main/notebooks/jcc/01-bow%2Bbinario%2Bsvm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuUrVBgeUso"
      },
      "source": [
        "# Baseline JCC: BoW+SVM\n",
        "\n",
        "En esta notebook se presetan los experimentos sobre la estrategia de representación y técnica de aprendizaje *baseline* utilizada para las JCC de  la Universidad Nacional de La Plata.\n",
        "\n",
        "Para ello vamos a preprocesar los correos y aplicar:\n",
        "- Bag of words,\n",
        "- Pesado binario/no binario,\n",
        "- Máquina de vector soporte (SVM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBLanwDJVnFF"
      },
      "source": [
        "## Instalación y Carga de librerías y funciones útiles\n",
        "\n",
        "### Instalación de librerías\n",
        "\n",
        "Se instalan las librerías que no están en el entorno de Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "644uDER_VnXj",
        "outputId": "11bfb6b4-9c7b-4539-8860-f68465093a14"
      },
      "source": [
        "# Se instala gensim que es el que tiene el modelo Word2Vec\n",
        "!pip install requests\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=ac225817a835892b8913785047b7191a872ae6d3332717693e325f9043dbf4b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43fDuhK2V1kx"
      },
      "source": [
        "### Funciones útiles\n",
        "\n",
        "Se cargan funciones útiles desde el repo https://github.com/jumafernandez/clasificacion_correos para la carga y balanceo del dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQvZz035bSMf"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_dataset.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_dataset.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_dataset import get_clases, cargar_dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDxjaGIfV-rT"
      },
      "source": [
        "También se carga la función para preprocesar el texto que se usó en los otros modelos desde el repo: https://github.com/jumafernandez/clasificacion_correos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0o2NndLWDVC"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_preprocesamiento.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_preprocesamiento.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_preprocesamiento import preprocesar_correos"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uv6R5UQWWmE"
      },
      "source": [
        "### Carga de datos\n",
        "\n",
        "Se carga el dataframe en memoria con el preprocesamiento de los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP4lJ_KVvBSO",
        "outputId": "8fd188e0-9a8b-4d9b-a03d-686a25f65aa3"
      },
      "source": [
        "import warnings\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Defino la cantidad de clases a utilizar\n",
        "CANTIDAD_CLASES = 4\n",
        "\n",
        "# Constantes con los datos\n",
        "DS_DIR = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/data/consolidado_jcc/'\n",
        "TRAIN_FILE = 'correos-train-80.csv'\n",
        "TEST_FILE = 'correos-test-20.csv'\n",
        "\n",
        "# Chequeo sobre si los archivos están en el working directory\n",
        "download_files = not(path.exists(TRAIN_FILE))\n",
        "\n",
        "etiquetas = get_clases()\n",
        "train_df, test_df, etiquetas = cargar_dataset(DS_DIR, TRAIN_FILE, TEST_FILE, download_files, 'clase', etiquetas, CANTIDAD_CLASES, 'Otras Consultas')\n",
        "\n",
        "# Se ejecuta el preprocesamiento de correos sobre el campo Consulta de train y test\n",
        "import pandas as pd\n",
        "train_df['Consulta'] = pd.Series(preprocesar_correos(train_df['Consulta']))\n",
        "test_df['Consulta'] = pd.Series(preprocesar_correos(test_df['Consulta']))\n",
        "\n",
        "# Cambio los integers por las etiquetas\n",
        "train_df['clase'] = etiquetas[train_df['clase']]\n",
        "test_df['clase'] = etiquetas[test_df['clase']]\n",
        "\n",
        "# Las vuelvo a pasar a números 0-N para evitar conflictos con simpletransformers\n",
        "# Este paso está fijo para estos experimentos\n",
        "dict_clases_id = {'Otras Consultas': 0,\n",
        "                            'Ingreso a la Universidad': 1,\n",
        "                            'Boleto Universitario': 2,\n",
        "                            'Requisitos de Ingreso': 3}\n",
        "\n",
        "train_df['clase'].replace(dict_clases_id, inplace=True)\n",
        "test_df['clase'].replace(dict_clases_id, inplace=True)\n",
        "\n",
        "# Muestro salida por consola\n",
        "print('Existen {} clases: {}.'.format(len(train_df.clase.unique()), train_df.clase.unique()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se inicia descarga de los datasets.\n",
            "\n",
            "El conjunto de entrenamiento tiene la dimensión: (800, 24)\n",
            "El conjunto de testeo tiene la dimensión: (200, 24)\n",
            "Existen 4 clases: [0 1 2 3].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17obw6uxVN21"
      },
      "source": [
        "## SVM\n",
        "\n",
        "Se carga en memoria la función _grid_search_por_estrategia_representacion_ que va a iterar ajustando los hiperparámetros para las técnica de __SVM__:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XF6H0BGX9F9"
      },
      "source": [
        "import requests\n",
        "\n",
        "# Se hace el request del raw del script python\n",
        "url = 'https://raw.githubusercontent.com/jumafernandez/clasificacion_correos/main/scripts/jcc/funciones_clasificacion_texto.py'\n",
        "r = requests.get(url)\n",
        "\n",
        "# Se guarda en el working directory\n",
        "with open('funciones_clasificacion_texto.py', 'w') as f:\n",
        "    f.write(r.text)\n",
        "\n",
        "# Se importan las funciones a utilizar\n",
        "from funciones_clasificacion_texto import gridsearch_por_estrategia_representacion"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiAo2N8TX-ao"
      },
      "source": [
        "Se define el espacio de búsqueda para el ajuste de hiperparámetros del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3TOc1GcX-rg"
      },
      "source": [
        "# Defino una lista con los esquemas de representación\n",
        "estrategias_representacion = ['BASELINE', 'BOW', 'TFIDF', '3-4-NGRAM-CHARS', '1-2-NGRAM-WORDS']\n",
        "modelo = 'SVM'\n",
        "\n",
        "# Defino los parámetros para GridSearchCV\n",
        "params_svm = {'SVM__C': [0.01, 0.1, 1, 10, 100, 1000], \n",
        "              'SVM__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'SVM__class_weight': [None, 'balanced'],\n",
        "              'SVM__kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "              }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmnm8yPmYGAR"
      },
      "source": [
        "Se ejecuta el ajuste de hiperparámetros para cada estrategia de representación en función del espacio de búsqueda:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFSOquuAYGPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2eca00d-1658-4f1f-b88a-25a761d9f00d"
      },
      "source": [
        "for estrategia in estrategias_representacion:\n",
        "  # Llamo a la función que realiza el gridsearch por estrategia  \n",
        "  gridsearch_por_estrategia_representacion(train_df, test_df, estrategia, modelo, params_svm, 'drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estrategia de representación: BASELINE\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   22.4s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 13.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 13.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n",
            "Estrategia de representación: BASELINE\n",
            "Parámetros: {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': 'BASELINE', 'accuracy': 0.85, 'precision': 0.8351234567901235, 'recall': 0.8278361456973765, 'f1_score': 0.83124883351997}\n",
            "Accuracy Test-Set: 0.85\n",
            "Estrategia de representación: BOW\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   22.6s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 13.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 13.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: BOW\n",
            "Parámetros: {'SVM__C': 10, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': 'BOW', 'accuracy': 0.85, 'precision': 0.8351234567901235, 'recall': 0.8278361456973765, 'f1_score': 0.83124883351997}\n",
            "Accuracy Test-Set: 0.85\n",
            "Estrategia de representación: TFIDF\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   22.4s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 14.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 14.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: TFIDF\n",
            "Parámetros: {'SVM__C': 10, 'SVM__class_weight': None, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': 'TFIDF', 'accuracy': 0.87, 'precision': 0.8646125116713351, 'recall': 0.8295386272763057, 'f1_score': 0.8412555432372505}\n",
            "Accuracy Test-Set: 0.87\n",
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 30.7min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 47.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 67.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 70.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: 3-4-NGRAM-CHARS\n",
            "Parámetros: {'SVM__C': 1, 'SVM__class_weight': 'balanced', 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': '3-4-NGRAM-CHARS', 'accuracy': 0.85, 'precision': 0.8529623477297896, 'recall': 0.8233053305434129, 'f1_score': 0.8355941468337398}\n",
            "Accuracy Test-Set: 0.85\n",
            "Estrategia de representación: 1-2-NGRAM-WORDS\n",
            "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 32.1min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed: 50.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed: 72.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1200 out of 1200 | elapsed: 75.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Estrategia de representación: 1-2-NGRAM-WORDS\n",
            "Parámetros: {'SVM__C': 1000, 'SVM__class_weight': None, 'SVM__gamma': 0.0001, 'SVM__kernel': 'rbf', 'clasificador': 'SVM', 'estrategia': '1-2-NGRAM-WORDS', 'accuracy': 0.855, 'precision': 0.8357118983957219, 'recall': 0.824452007672281, 'f1_score': 0.8285959592377169}\n",
            "Accuracy Test-Set: 0.855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a1K2447qjxE"
      },
      "source": [
        "# Referencias\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "- https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05"
      ]
    }
  ]
}